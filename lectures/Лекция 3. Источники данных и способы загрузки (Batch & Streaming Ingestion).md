## 1. Откуда берутся данные в аналитической платформе

Аналитическая платформа не генерирует данные сама. Она получает их из источников — систем, в которых данные изначально создаются и живут.

### Почему понимание источников критично

Если не понимать природу источника, невозможно правильно построить пайплайн. Источник диктует способ извлечения данных, частоту обновлений, технологию загрузки и формат данных на входе.

Источник диктует:

- можно ли получить только изменения или нужно каждый раз тянуть всё;
- какие гарантии консистентности есть;
- как часто данные меняются;
- какие технические ограничения существуют.

### Основные типы источников данных

**Операционные базы данных (OLTP БД)**

Базы, которые обслуживают работу приложений: PostgreSQL, MySQL, MongoDB, Oracle, MS SQL Server.

Содержат таблицы с операционными данными: пользователи, заказы, платежи, товары, транзакции.

Напрямую из production БД тянуть опасно:

- аналитические запросы тормозят production;
- аналитике нужна история, а в OLTP часто хранится актуальное состояние;
- аналитике нужны данные в другом формате.

Данные из OLTP выгружаются в аналитическую платформу отдельными процессами.

**Внешние API**

Данные приходят из внешних сервисов через API: платёжные системы, рекламные платформы, CRM-системы, внешние справочники.

Данные приходят по запросу. Часто есть лимиты на запросы. Формат обычно JSON или XML. Нужно обрабатывать ошибки, таймауты, повторы.

**Файлы и выгрузки**

Данные поступают в виде файлов: CSV, Excel, JSON, XML дампы, логи приложений.

Файлы складываются в хранилище (FTP, S3, локальная папка), откуда их забирают и обрабатывают.

**Потоки событий (event streams)**

Данные генерируются постоянно в реальном времени: клики пользователей, действия в приложениях, события IoT-устройств, логи серверов.

Особенности потоков:

- данные приходят непрерывно;
- их нельзя запросить заново;
- объёмы могут быть огромными;
- нужна специальная инфраструктура для обработки.

**Изменения данных в БД (CDC — Change Data Capture)**

Отслеживание не всего слепка базы, а только изменений: какие строки добавились, обновились, удалились.

CDC позволяет:

- не тянуть всю таблицу каждый раз;
- отслеживать изменения почти в реальном времени;
- строить инкрементальные пайплайны.

### Как источники связаны с архитектурой платформы

Источники — входная точка аналитической платформы. От природы источника зависит механизм загрузки, частота обновлений, место хранения сырых данных, возможные проблемы качества.

Типичные схемы:

- OLTP БД → batch-выгрузка → RAW слой → Staging → витрины;
- API → batch-запросы по расписанию → RAW слой → обработка;
- Event streams → Kafka → streaming обработка → RAW слой;
- CDC → Debezium → Kafka → инкрементальная обработка → Staging.

### Главный принцип работы с источниками

Источник не контролируется. Источник может измениться, сломаться, начать отдавать некорректные данные.

Данные из источника всегда сначала сохраняются в RAW слой в исходном виде. Только потом начинается обработка, очистка, валидация. Если что-то пошло не так — можно вернуться к RAW и пересчитать.

Это защита от потери данных и основа воспроизводимости пайплайнов.

### Инвентаризация источников

Первый шаг любого аналитического проекта — инвентаризация источников:

- какие источники есть;
- какие данные в них хранятся;
- как часто они обновляются;
- как к ним можно подключиться;
- какие ограничения у них есть.

Только после этого можно проектировать пайплайны загрузки.

---

## 2. Batch vs Streaming: две парадигмы загрузки данных

Существуют два фундаментально разных подхода к загрузке данных в аналитическую платформу: batch и streaming. Эти подходы отличаются не только технически, но и концептуально — они решают разные задачи и имеют разные ограничения.

### Batch Ingestion: загрузка порциями

Batch ingestion — это загрузка данных **дискретными порциями** с определённой периодичностью.

Принцип работы:

- данные накапливаются в источнике;
- по расписанию запускается процесс загрузки;
- процесс забирает данные за определённый период;
- данные обрабатываются и складываются в целевое хранилище;
- процесс завершается до следующего запуска.

Периодичность может быть разной:

- раз в день (ночная загрузка);
- раз в час;
- раз в 15 минут;
- по событию.

Ключевая характеристика batch: между загрузками есть **задержка**. Данные в аналитической системе всегда отстают от источника на время между загрузками.

### Streaming Ingestion: непрерывная загрузка

Streaming ingestion — это **непрерывная** загрузка данных по мере их появления в источнике.

Принцип работы:

- данные появляются в источнике;
- мгновенно (с задержкой в секунды) попадают в поток;
- поток обрабатывается непрерывно работающим процессом;
- данные складываются в целевое хранилище почти сразу.

Ключевая характеристика streaming: данные в аналитической системе появляются **почти в реальном времени**. Задержка измеряется секундами или миллисекундами.

### Фундаментальная разница

Разница между batch и streaming — не в скорости, а в **природе обработки**.

Batch обрабатывает **конечные наборы данных**:

- есть начало и конец порции;
- можно посчитать размер порции;
- можно обработать порцию несколько раз;
- можно гарантировать полноту порции.

Streaming обрабатывает **бесконечные потоки данных**:

- нет конца потока;
- нельзя узнать размер заранее;
- данные обрабатываются один раз при прохождении;
- полнота определяется временными окнами.

### Когда использовать batch

Batch подходит когда:

- данные в источнике обновляются с известной периодичностью;
- задержка в несколько часов или минут допустима;
- объём данных за период предсказуем;
- важна гарантия полноты загрузки;
- источник не поддерживает streaming.

Типичные сценарии batch:

- ежедневная выгрузка таблиц из OLTP БД;
- загрузка отчётов от партнёров;
- обновление справочников;
- пересчёт витрин;
- загрузка данных из API с лимитами.

### Когда использовать streaming

Streaming подходит когда:

- данные генерируются непрерывно;
- задержка должна быть минимальной;
- объёмы данных очень большие;
- важна актуальность данных;
- источник генерирует события.

Типичные сценарии streaming:

- события из мобильных приложений;
- клики на сайте;
- логи серверов;
- данные с IoT-устройств;
- изменения в БД через CDC.

### Задержка и свежесть данных

Batch имеет предсказуемую задержку:

- если загрузка раз в день — данные отстают максимум на сутки;
- если раз в час — максимум на час;
- задержка контролируется расписанием.

Streaming имеет минимальную задержку:

- данные появляются в системе через секунды;
- задержка определяется скоростью обработки;
- задержка непредсказуема при сбоях.

### Сложность реализации

Batch проще:

- понятная модель: взял данные, обработал, положил;
- легче отлаживать;
- легче пересчитывать;
- меньше требований к инфраструктуре.

Streaming сложнее:

- нужна инфраструктура потоковой обработки;
- сложнее отлаживать;
- сложнее обеспечить ровно-один раз обработку;
- выше требования к мониторингу.

### Стоимость

Batch дешевле:

- процессы запускаются периодически;
- между запусками ресурсы не используются;
- легче масштабировать вертикально.

Streaming дороже:

- процессы работают постоянно;
- нужны постоянно работающие сервисы;
- требуется больше памяти для буферизации.

### Гарантии обработки

Batch даёт сильные гарантии:

- можно проверить, что все данные за период загружены;
- можно пересчитать порцию;
- можно откатить загрузку.

Streaming даёт слабые гарантии:

- данные могут быть потеряны при сбое;
- данные могут быть обработаны дважды;
- нужны дополнительные механизмы для гарантий.

### Комбинирование подходов

В реальных системах часто используются оба подхода одновременно:

- streaming для событий в реальном времени;
- batch для ежедневных агрегатов и отчётов.

Lambda-архитектура:

- streaming слой для актуальных данных;
- batch слой для исторических данных;
- serving слой объединяет результаты.

Kappa-архитектура:

- всё через streaming;
- batch эмулируется через пересчёт потоков.

### Влияние на архитектуру слоёв

Batch естественно ложится на слоистую архитектуру:

- RAW пополняется порциями;
- Staging пересчитывается порциями;
- витрины обновляются порциями.

Streaming требует адаптации:

- RAW пополняется непрерывно;
- Staging обновляется инкрементально;
- витрины могут обновляться в реальном времени или батчами.

---

## 3. Batch Ingestion: концепция и применение

Batch ingestion — это процесс загрузки данных **дискретными порциями** по расписанию или по событию. Каждая порция обрабатывается как отдельная задача с чётким началом и концом.

### Концептуальная модель batch-загрузки

Batch-загрузка состоит из нескольких этапов:

**Extraction (извлечение)**

Данные извлекаются из источника. Источник может быть:

- реляционная БД;
- NoSQL БД;
- API;
- файловое хранилище;
- FTP-сервер.

Извлечение может быть:

- полным (full load) — вся таблица целиком;
- инкрементальным (incremental load) — только новые или изменённые записи.

**Transformation (трансформация)**

Данные преобразуются перед загрузкой:

- изменение типов данных;
- фильтрация ненужных записей;
- обогащение данными из других источников;
- агрегация;
- очистка.

Трансформация может происходить:

- до загрузки в хранилище (ETL);
- после загрузки в хранилище (ELT).

**Loading (загрузка)**

Данные загружаются в целевое хранилище:

- RAW слой в S3/MinIO;
- таблица в ClickHouse;
- таблица в PostgreSQL;
- файл в HDFS.

Загрузка может быть:

- append (добавление новых записей);
- upsert (добавление новых и обновление существующих);
- replace (полная замена данных).

### Полная загрузка (Bulk Lowad)

Полная загрузка означает извлечение всех данных из источника каждый раз.

Когда используется:

- таблица небольшая (до нескольких миллионов записей);
- данные в таблице часто меняются непредсказуемо;
- нет возможности отследить изменения;
- проще пересчитать всё, чем отслеживать изменения.

Преимущества:

- простая логика;
- гарантия полноты данных;
- не нужно отслеживать изменения в источнике.

Недостатки:

- большая нагрузка на источник;
- долгое время выполнения;
- неэффективно для больших таблиц;
- избыточный трафик.

Технически полная загрузка выглядит так:

- подключение к источнику;
- SELECT всех записей из таблицы;
- сохранение в файл или прямая загрузка в целевую БД;
- замена старых данных новыми.

### Инкрементальная загрузка (Incremental Load)

Инкрементальная загрузка означает извлечение только новых или изменённых записей с момента последней загрузки.

Когда используется:

- таблица большая;
- изменения составляют малую часть от всех данных;
- есть возможность определить новые/изменённые записи;
- важна скорость загрузки.

Способы определения изменений:

**По timestamp-полю**

В таблице есть поле `updated_at` или `created_at`. При загрузке берутся записи, где `updated_at > last_load_timestamp`.

Преимущества:

- простая логика;
- не требует изменений в источнике.

Недостатки:

- поле должно корректно обновляться;
- не видно удалённых записей;
- возможны пропуски при одновременных обновлениях.

**По инкрементальному ключу**

В таблице есть автоинкрементное поле (обычно primary key). При загрузке берутся записи, где `id > last_loaded_id`.

Преимущества:

- гарантированная уникальность;
- не зависит от времени.

Недостатки:

- работает только для новых записей;
- не видно обновлений существующих записей;
- не видно удалений.

**По флагу изменения**

В таблице есть поле `is_processed` или `exported_at`. После загрузки флаг обновляется.

Преимущества:

- явный контроль обработанных записей.

Недостатки:

- требует изменения данных в источнике;
- может создавать нагрузку на источник при обновлении флагов.

**Через Change Data Capture (CDC)**

Используется механизм отслеживания изменений на уровне БД (binlog, WAL, triggers).

Преимущества:

- видны все типы изменений (insert, update, delete);
- минимальная нагрузка на источник;
- данные близки к реальному времени.

Недостатки:

- сложнее настроить;
- требует прав на чтение логов БД;
- требует специальных инструментов.

### Расписание и частота загрузок

Batch-загрузки выполняются по расписанию. Частота зависит от требований бизнеса и характера данных.

**Ежедневная загрузка**

Самый распространённый паттерн. Данные загружаются раз в сутки, обычно ночью.

Когда подходит:

- отчётность по дням;
- данные меняются равномерно в течение дня;
- допустима задержка до суток.

Типичное расписание: 02:00–04:00 ночи по местному времени, когда нагрузка на источник минимальна.

**Ежечасная загрузка**

Данные загружаются каждый час.

Когда подходит:

- нужна более высокая актуальность;
- объёмы данных за час умеренные;
- источник выдерживает частые запросы.

**Загрузка раз в N минут**

Данные загружаются каждые 15, 30 минут.

Когда подходит:

- требования к актуальности высокие, но streaming избыточен;
- инкрементальные загрузки быстрые;
- источник стабилен.

**Триггерная загрузка**

Загрузка запускается по событию: появление файла, вызов API, сигнал от другой системы.

Когда подходит:

- данные появляются нерегулярно;
- важна оперативная реакция на появление данных.

### Идемпотентность batch-загрузок

Идемпотентность — свойство операции давать одинаковый результат при повторном выполнении.

Batch-загрузка должна быть идемпотентной:

- если загрузка упала и перезапустилась, результат должен быть корректным;
- повторная загрузка за тот же период не должна создавать дубли;
- откат и повтор загрузки должны быть безопасны.

Способы обеспечения идемпотентности:

**Партиционирование по дате загрузки**

Каждая загрузка пишет данные в свою партицию по дате. При повторной загрузке партиция перезаписывается.

**Использование upsert вместо insert**

При загрузке данные добавляются или обновляются по ключу, но не дублируются.

**Staging-таблицы**

Данные сначала загружаются во временную таблицу, проверяются, затем переносятся в финальную таблицу атомарной операцией.

**Транзакционность**

Загрузка выполняется в транзакции. Если что-то пошло не так — откат, данные остаются в прежнем состоянии.

### Управление состоянием загрузок

Batch-загрузки должны сохранять своё состояние:

- когда была последняя успешная загрузка;
- какие данные были загружены;
- какие ошибки возникали.

Способы хранения состояния:

**Метаданные в оркестраторе**

Airflow, Prefect и другие оркестраторы хранят историю запусков, статусы задач, метаданные.

**Таблица контрольных точек**

Отдельная таблица в БД с информацией о загрузках:

- имя источника;
- дата последней загрузки;
- последний загруженный ID;
- статус загрузки;
- количество загруженных записей.

**Файлы-маркеры**

После успешной загрузки создаётся файл-маркер с меткой времени или контрольной суммой.

### Обработка ошибок и повторы

Batch-загрузки должны корректно обрабатывать ошибки:

**Типы ошибок**

- недоступность источника (сеть, таймауты);
- изменение схемы источника;
- битые данные в источнике;
- нехватка места в целевом хранилище;
- ошибки валидации данных.

**Стратегии обработки**

Повтор с экспоненциальной задержкой:

- первая попытка сразу;
- вторая через 1 минуту;
- третья через 2 минуты;
- четвёртая через 4 минуты.

Алертинг и ручное вмешательство:

- после N неудачных попыток отправляется уведомление;
- загрузка останавливается до разбора проблемы.

Частичная загрузка:

- если часть данных загружена успешно, она сохраняется;
- повтор загружает только несохранённую часть.

Dead letter queue:

- записи, которые не удалось обработать, складываются в отдельное место;
- они обрабатываются отдельно или вручную.

### Мониторинг batch-загрузок

Критически важно мониторить batch-процессы:

**Метрики**

- время выполнения загрузки;
- количество загруженных записей;
- количество ошибок;
- размер загруженных данных;
- задержка между источником и хранилищем.

**Алерты**

- загрузка не завершилась вовремя;
- загрузка упала с ошибкой;
- количество загруженных записей резко изменилось;
- нет данных за период.

**Логирование**

Каждая загрузка должна логировать:

- начало и конец выполнения;
- параметры загрузки;
- количество обработанных записей;
- ошибки и предупреждения.

---

## 4. Оркестрация batch-загрузок: роль Airflow

Batch-загрузки не существуют изолированно. Они являются частью сложных пайплайнов, где одни задачи зависят от других. Для управления этими пайплайнами используются оркестраторы. Airflow — один из самых популярных оркестраторов для data-пайплайнов.

### Что такое оркестрация

Оркестрация — это управление выполнением множества задач с учётом их зависимостей, расписаний и условий.

Без оркестрации:

- каждая задача запускается отдельным скриптом или cron-джобом;
- зависимости между задачами не видны;
- сложно отследить, что выполнилось, а что нет;
- при ошибке непонятно, что делать дальше;
- нет единого места для мониторинга.

С оркестрацией:

- все задачи описаны в едином месте;
- зависимости явно заданы;
- есть визуализация пайплайна;
- автоматическая обработка ошибок и повторы;
- единый интерфейс для мониторинга и управления.

### Почему нужен оркестратор для batch-загрузок

Реальные data-пайплайны сложные:

- загрузка из нескольких источников должна завершиться до начала трансформации;
- трансформация данных состоит из нескольких шагов;
- витрины пересчитываются после обновления Staging слоя;
- некоторые задачи зависят от внешних условий.

Оркестратор решает эти проблемы:

**Управление зависимостями**

Задача B запускается только после успешного завершения задачи A.

**Управление расписаниями**

Пайплайн запускается автоматически по расписанию: каждый день в 02:00, каждый час в начале часа.

**Обработка ошибок**

Если задача упала, оркестратор может автоматически перезапустить её или отправить уведомление.

**Параллельное выполнение**

Независимые задачи выполняются параллельно, ускоряя пайплайн.

**Мониторинг и логирование**

Все запуски, логи, метрики собираются в едином интерфейсе.

**Повторяемость**

Любой запуск пайплайна можно повторить с теми же параметрами.

### Роль Airflow в data-инженерии

Apache Airflow — платформа для программного создания, планирования и мониторинга workflow. Изначально разработана в Airbnb, затем стала проектом Apache.

Airflow решает задачи:

- описание сложных data-пайплайнов как кода;
- автоматический запуск пайплайнов по расписанию;
- управление зависимостями между задачами;
- распределённое выполнение задач;
- мониторинг выполнения;
- обработка ошибок и повторы.

Airflow стал стандартом де-факто для оркестрации batch-пайплайнов в data-инженерии.

### Философия Airflow: пайплайны как код

Ключевой принцип Airflow: пайплайны описываются кодом на Python, а не через графический интерфейс или конфигурационные файлы.

Преимущества:

- пайплайны версионируются в Git;
- легко делать code review;
- можно применять практики разработки ПО;
- легко параметризовать и переиспользовать;
- можно генерировать пайплайны программно.

Пайплайн в Airflow описывается как DAG (Directed Acyclic Graph) — направленный ациклический граф.

### Основные абстракции Airflow

**DAG (Directed Acyclic Graph)**

Граф задач с зависимостями. Представляет весь пайплайн целиком.

DAG определяет:

- какие задачи выполняются;
- в каком порядке;
- по какому расписанию;
- с какими параметрами.

**Task (задача)**

Атомарная единица работы в DAG. Задача выполняет одно действие: загружает данные, трансформирует, отправляет уведомление.

Задачи связаны зависимостями: task A → task B означает, что B выполняется после успешного завершения A.

**Operator (оператор)**

Шаблон для создания задач. Определяет, что конкретно делает задача.

Есть операторы для разных действий:

- BashOperator — выполнение bash-команды;
- PythonOperator — выполнение Python-функции;
- SQLOperator — выполнение SQL-запроса;
- специализированные операторы для разных систем.

**Sensor (сенсор)**

Специальный тип оператора, который ждёт выполнения условия перед продолжением.

Примеры условий:

- появление файла;
- доступность внешней системы;
- определённое время суток;
- статус внешней задачи.

**Executor (исполнитель)**

Компонент, который определяет, как задачи выполняются:

- локально на одной машине;
- распределённо на кластере;
- в Kubernetes;
- через Celery.

### Как Airflow управляет batch-загрузками

Типичный batch-пайплайн в Airflow:

1. Сенсор ждёт доступности источника данных
2. Задача извлекает данные из источника
3. Задача сохраняет данные в RAW слой
4. Задача валидирует загруженные данные
5. Задача трансформирует данные в Staging
6. Задача обновляет витрины
7. Задача отправляет уведомление об успехе

Все эти шаги описаны в одном DAG, связаны зависимостями, выполняются последовательно или параллельно по мере готовности.

### Обработка ошибок в Airflow

Airflow предоставляет механизмы для обработки ошибок:

**Автоматические повторы**

Задача может быть перезапущена автоматически при падении. Настраивается количество попыток и задержка между ними.

**Алертинг**

При ошибке Airflow может отправить уведомление: email, Slack, Telegram, PagerDuty.

**Обработчики ошибок**

Можно задать задачи, которые выполняются только при ошибках: откат изменений, очистка временных данных, отправка детального отчёта.

**SLA (Service Level Agreement)**

Можно задать ожидаемое время выполнения задачи. Если задача выполняется дольше — отправляется уведомление.

### Мониторинг в Airflow

Airflow предоставляет веб-интерфейс для мониторинга:

**Визуализация DAG**

Граф задач с зависимостями, цветовая индикация статусов (успех, ошибка, выполняется).

**История запусков**

Таблица всех запусков DAG с датами, длительностью, статусами.

**Логи задач**

Каждая задача пишет логи, которые доступны через интерфейс.

**Метрики**

Время выполнения задач, частота ошибок, длина очереди задач.

**Gantt-диаграмма**

Временная диаграмма выполнения задач, показывает параллелизм и узкие места.

### Масштабирование Airflow

Airflow можно масштабировать горизонтально:

**LocalExecutor**

Задачи выполняются на одной машине параллельно через multiprocessing. Подходит для небольших инсталляций.

**CeleryExecutor**

Задачи распределяются по кластеру worker-нодов через Celery. Подходит для средних и крупных инсталляций.

**KubernetesExecutor**

Каждая задача запускается в отдельном Kubernetes pod. Динамическое масштабирование, изоляция задач.

---
## 5. Архитектура Airflow: компоненты и принципы работы

Airflow — это не монолитное приложение, а распределённая система из нескольких компонентов, которые взаимодействуют друг с другом. Понимание архитектуры критично для правильного развёртывания и эксплуатации.

### Основные компоненты Airflow

**Webserver**

Веб-сервер предоставляет пользовательский интерфейс для взаимодействия с Airflow.

Функции:

- визуализация DAG и задач;
- просмотр логов выполнения;
- ручной запуск и остановка DAG;
- управление конфигурацией;
- мониторинг статусов.

Технически это Flask-приложение, которое читает данные из метадаты и отображает их в браузере.

**Scheduler**

Планировщик — сердце Airflow. Отвечает за запуск задач по расписанию и управление зависимостями.

Функции:

- парсинг DAG-файлов и обновление метаданных;
- определение задач, готовых к выполнению;
- постановка задач в очередь на выполнение;
- отслеживание статусов задач;
- обработка зависимостей между задачами.

Scheduler работает непрерывно в фоновом режиме. Это критический компонент — если он останавливается, новые задачи не запускаются.

**Executor**

Исполнитель определяет, как задачи физически выполняются: локально, на кластере, в контейнерах.

Типы Executor:

- SequentialExecutor — задачи выполняются последовательно, одна за другой. Подходит только для разработки и тестирования.
- LocalExecutor — задачи выполняются параллельно на той же машине через multiprocessing.
- CeleryExecutor — задачи распределяются по worker-нодам через очередь Celery.
- KubernetesExecutor — каждая задача запускается в отдельном Kubernetes pod.
- DaskExecutor — задачи выполняются через Dask-кластер.

**Worker**

Worker-ноды выполняют задачи. Количество и конфигурация зависят от выбранного Executor.

При LocalExecutor worker-процессы запускаются на той же машине, что и Scheduler.

При CeleryExecutor worker-ноды — отдельные машины или контейнеры, которые получают задачи из очереди.

При KubernetesExecutor worker — это pod, который создаётся для выполнения конкретной задачи и удаляется после завершения.

**Metadata Database**

База данных метаданных хранит всю информацию о состоянии Airflow:

- определения DAG;
- задачи и их зависимости;
- история запусков;
- статусы задач;
- логи;
- переменные и соединения;
- пользователи и права доступа.

Поддерживаемые СУБД:

- PostgreSQL (рекомендуется для production);
- MySQL;
- SQLite (только для разработки, не для production).

Metadata Database — единственный источник правды о состоянии системы. Все компоненты читают и записывают в неё.

**DAG Directory**

Директория с Python-файлами, содержащими определения DAG.

Scheduler периодически сканирует эту директорию, парсит файлы и обновляет метаданные.

Важно:

- DAG-файлы должны быть доступны всем компонентам;
- изменения в файлах подхватываются автоматически;
- ошибки в DAG-файлах не ломают Airflow, но DAG не загружается.

**Message Broker (для CeleryExecutor)**

Брокер сообщений используется при CeleryExecutor для передачи задач worker-нодам.

Поддерживаемые брокеры:

- RabbitMQ;
- Redis.

Broker хранит очередь задач. Scheduler кладёт задачи в очередь, worker-ноды забирают их оттуда и выполняют.

### Как компоненты взаимодействуют

Цикл выполнения задачи:

1. Scheduler парсит DAG-файлы из DAG Directory
2. Scheduler записывает информацию о DAG в Metadata Database
3. Scheduler проверяет расписание и зависимости
4. Scheduler определяет задачи, готовые к выполнению
5. Scheduler передаёт задачи Executor
6. Executor помещает задачи в очередь или запускает напрямую
7. Worker забирает задачу и выполняет
8. Worker записывает результат и логи в Metadata Database
9. Scheduler видит завершение задачи и запускает зависимые задачи
10. Webserver читает данные из Metadata Database и отображает в UI

### Жизненный цикл DAG

**Парсинг**

Scheduler периодически сканирует DAG Directory и парсит Python-файлы. Из каждого файла извлекаются объекты DAG.

Частота парсинга настраивается параметром `dag_dir_list_interval`. По умолчанию — каждые 30 секунд.

**Сериализация**

После парсинга DAG сериализуется и сохраняется в Metadata Database. Это позволяет Webserver и другим компонентам читать DAG без повторного парсинга.

**Создание DagRun**

Когда наступает время выполнения по расписанию, Scheduler создаёт DagRun — экземпляр выполнения DAG для конкретного execution_date.

DagRun содержит:

- execution_date — для какого периода данных выполняется DAG;
- run_id — уникальный идентификатор запуска;
- статус (running, success, failed);
- время начала и завершения.

**Создание TaskInstance**

Для каждой задачи в DAG создаётся TaskInstance — экземпляр выполнения конкретной задачи в рамках DagRun.

TaskInstance проходит через состояния:

- none — задача ещё не запланирована;
- scheduled — задача запланирована к выполнению;
- queued — задача в очереди на выполнение;
- running — задача выполняется;
- success — задача завершилась успешно;
- failed — задача завершилась с ошибкой;
- skipped — задача пропущена;
- up_for_retry — задача будет перезапущена.

**Проверка зависимостей**

Scheduler проверяет зависимости каждой TaskInstance:

- завершились ли успешно upstream-задачи;
- выполнены ли условия сенсоров;
- соблюдены ли ограничения на параллелизм.

Только после выполнения всех условий задача переходит в состояние queued.

**Выполнение**

Executor забирает задачи в состоянии queued и запускает их на Worker.

Worker выполняет код, определённый в операторе задачи: Python-функцию, bash-команду, SQL-запрос.

**Завершение**

После выполнения Worker записывает результат в Metadata Database:

- success или failed;
- return value задачи;
- логи выполнения;
- время начала и завершения;
- количество попыток.

Scheduler видит завершение и переводит зависимые задачи в состояние scheduled.

### Управление состоянием

Всё состояние Airflow хранится в Metadata Database. Это делает систему устойчивой к сбоям:

- если Scheduler падает, после перезапуска он восстанавливает состояние из БД;
- если Worker падает во время выполнения задачи, Scheduler видит, что задача зависла, и может перезапустить её;
- историю всех запусков можно восстановить из БД.

Важные таблицы в Metadata Database:

- `dag` — метаданные DAG;
- `dag_run` — запуски DAG;
- `task_instance` — экземпляры задач;
- `task_fail` — история ошибок;
- `log` — логи выполнения;
- `connection` — параметры подключений к внешним системам;
- `variable` — переменные конфигурации.

### Параллелизм и ограничения

Airflow позволяет контролировать параллелизм на разных уровнях.

**Глобальный параллелизм**

Параметр `parallelism` определяет максимальное количество TaskInstance, которые могут выполняться одновременно в рамках всего Airflow.

**Параллелизм DAG**

Параметр `dag_concurrency` (или `max_active_tasks_per_dag`) определяет максимальное количество TaskInstance одного DAG, которые могут выполняться одновременно.

**Параллелизм задачи**

Параметр `task_concurrency` (или `max_active_tis_per_dag`) определяет максимальное количество экземпляров одной задачи, которые могут выполняться одновременно.

**Количество активных DagRun**

Параметр `max_active_runs` определяет, сколько DagRun одного DAG могут выполняться одновременно.

Эти ограничения предотвращают перегрузку системы и позволяют контролировать нагрузку на внешние системы.

### Хранение логов

Логи выполнения задач хранятся отдельно от Metadata Database.

Способы хранения логов:

**Локальная файловая система**

По умолчанию логи пишутся в директорию на диске. Webserver читает логи из этой директории.

Проблема: если Worker-ноды распределены, логи размазаны по разным машинам.

**Удалённое хранилище (S3, GCS, Azure Blob)**

Логи пишутся в объектное хранилище. Все компоненты имеют доступ к логам через API.

Преимущества:

- централизованное хранение;
- не зависит от состояния Worker-нод;
- легко интегрировать с системами логирования.

**Elasticsearch**

Логи отправляются в Elasticsearch. Webserver читает их через Elasticsearch API.

Преимущества:

- полнотекстовый поиск по логам;
- агрегация и анализ;
- интеграция с Kibana для визуализации.

### Безопасность и аутентификация

Airflow поддерживает различные механизмы безопасности:

**Аутентификация**

Способы аутентификации пользователей:

- логин/пароль (локальная БД);
- LDAP/Active Directory;
- OAuth (Google, GitHub и др.);
- Kerberos.

**Авторизация (RBAC — Role-Based Access Control)**

Управление правами доступа на основе ролей:

- Admin — полный доступ;
- User — просмотр и запуск DAG;
- Viewer — только просмотр;
- Op — операционное управление без изменения DAG.

Можно создавать кастомные роли с гранулярными правами.

**Шифрование соединений**

Параметры подключений к внешним системам (БД, API) хранятся в Metadata Database.

Можно включить шифрование этих параметров через Fernet key. Без ключа расшифровать параметры невозможно.

### High Availability и отказоустойчивость

Для production-инсталляций критична отказоустойчивость.

**Несколько Scheduler**

Начиная с Airflow 2.0 можно запускать несколько экземпляров Scheduler одновременно. Они координируются через Metadata Database.

Если один Scheduler падает, другие продолжают работу.

**Резервирование Metadata Database**

Metadata Database — единая точка отказа. Необходимо обеспечить её отказоустойчивость:

- репликация;
- автоматический failover;
- регулярные бэкапы.

**Мониторинг компонентов**

Необходимо мониторить:

- работоспособность Scheduler;
- доступность Metadata Database;
- длину очереди задач;
- количество падающих задач;
- время выполнения задач.

При проблемах — автоматические алерты.

### Типовая архитектура для production

Минимальная production-инсталляция:

- 2+ Scheduler (для отказоустойчивости);
- PostgreSQL с репликацией (Metadata Database);
- Redis или RabbitMQ (Message Broker для Celery);
- N Worker-нод (по потребностям);
- 1+ Webserver (за load balancer);
- S3 или аналог для хранения логов;
- Мониторинг (Prometheus + Grafana).

Все компоненты разнесены по разным машинам или контейнерам. DAG-файлы синхронизируются между нодами через Git или общую файловую систему.

---

## 6. DAG в Airflow: структура и логика

DAG (Directed Acyclic Graph) — центральная абстракция в Airflow. Это программное описание data-пайплайна: какие задачи выполняются, в каком порядке, с какой периодичностью.

### Что такое DAG

DAG — направленный ациклический граф. Направленный означает, что зависимости между задачами имеют направление: A → B означает, что B выполняется после A. Ациклический означает, что в графе нет циклов: невозможна ситуация A → B → C → A.

В контексте Airflow:

- узлы графа — задачи (Task);
- рёбра графа — зависимости между задачами;
- граф в целом — пайплайн обработки данных.

### Структура DAG-файла

DAG определяется в Python-файле. Файл размещается в DAG Directory, откуда Scheduler его считывает.

Базовая структура:

```python
from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime, timedelta

default_args = {
    'owner': 'data_team',
    'depends_on_past': False,
    'start_date': datetime(2024, 1, 1),
    'email_on_failure': True,
    'email_on_retry': False,
    'retries': 2,
    'retry_delay': timedelta(minutes=5),
}

dag = DAG(
    dag_id='example_pipeline',
    default_args=default_args,
    description='Пример data-пайплайна',
    schedule_interval='@daily',
    catchup=False,
    tags=['example', 'batch'],
)

def extract_data():
    # код извлечения данных
    pass

def transform_data():
    # код трансформации
    pass

def load_data():
    # код загрузки
    pass

task_extract = PythonOperator(
    task_id='extract',
    python_callable=extract_data,
    dag=dag,
)

task_transform = PythonOperator(
    task_id='transform',
    python_callable=transform_data,
    dag=dag,
)

task_load = PythonOperator(
    task_id='load',
    python_callable=load_data,
    dag=dag,
)

task_extract >> task_transform >> task_load
```

### Параметры DAG

**dag_id**

Уникальный идентификатор DAG. По нему DAG различаются в системе.

Соглашения по именованию:

- использовать snake_case;
- отражать назначение пайплайна;
- не использовать специальные символы.

**default_args**

Словарь с параметрами, которые применяются ко всем задачам DAG по умолчанию.

Основные параметры:

- `owner` — владелец DAG (для организации ответственности);
- `start_date` — дата, с которой DAG начинает выполняться;
- `end_date` — дата, после которой DAG перестаёт выполняться;
- `retries` — количество автоматических повторов при ошибке;
- `retry_delay` — задержка между повторами;
- `email` — адреса для уведомлений;
- `email_on_failure` — отправлять email при ошибке;
- `email_on_retry` — отправлять email при повторе.

**schedule_interval**

Периодичность запуска DAG.

Форматы:

- cron-выражение: `'0 2 * * *'` (каждый день в 02:00);
- preset: `'@daily'`, `'@hourly'`, `'@weekly'`;
- timedelta: `timedelta(hours=6)` (каждые 6 часов);
- `None` — DAG запускается только вручную.

**start_date**

Дата, с которой начинает работать расписание. Первый DagRun будет создан для этой даты.

Важно: `start_date` определяет не когда DAG запустится первый раз физически, а для какого периода данных будет первый запуск.

Если `start_date = 2024-01-01` и `schedule_interval = @daily`, то первый DagRun будет для данных за 2024-01-01, но физически запустится 2024-01-02.

**catchup**

Определяет, нужно ли выполнять DAG для всех пропущенных периодов между `start_date` и текущим моментом.

Если `catchup=True` и DAG создан сегодня, но `start_date` был месяц назад, Airflow создаст DagRun для всех дней между `start_date` и сегодня.

Если `catchup=False`, будет создан только DagRun для последнего периода.

**tags**

Метки для группировки и фильтрации DAG в UI.

**description**

Текстовое описание назначения DAG. Отображается в UI.

**max_active_runs**

Максимальное количество одновременно выполняющихся DagRun этого DAG.

**dagrun_timeout**

Максимальное время выполнения DagRun. Если превышено — DagRun помечается как failed.

### Execution Date и логические даты

Ключевая концепция Airflow — execution_date.

Execution_date — это не дата физического запуска DAG, а **логическая дата**, для которой DAG обрабатывает данные.

Если DAG запускается ежедневно в 02:00 для обработки данных за предыдущий день:

- физический запуск: 2024-01-02 02:00;
- execution_date: 2024-01-01.

Это позволяет:

- однозначно определять, за какой период обрабатываются данные;
- делать backfill (пересчёт исторических данных);
- гарантировать, что данные за период полностью собраны перед обработкой.

В Airflow 2.2+ введён новый термин — data_interval. Это интервал времени, за который обрабатываются данные:

- data_interval_start — начало интервала (старый execution_date);
- data_interval_end — конец интервала.

Для ежедневного DAG с execution_date = 2024-01-01:

- data_interval_start = 2024-01-01 00:00:00;
- data_interval_end = 2024-01-02 00:00:00.

### Зависимости между задачами

Зависимости определяют порядок выполнения задач.

Способы задания зависимостей:

**Операторы >> и <<**

```python
task_a >> task_b  # task_b выполняется после task_a
task_b << task_a  # то же самое
```

**Цепочки**

```python
task_a >> task_b >> task_c >> task_d
```

**Множественные зависимости**

```python
task_a >> [task_b, task_c]  # task_b и task_c выполняются после task_a параллельно
[task_b, task_c] >> task_d  # task_d выполняется после завершения и task_b, и task_c
```

**Метод set_upstream / set_downstream**

```python
task_b.set_upstream(task_a)  # task_b выполняется после task_a
task_a.set_downstream(task_b)  # то же самое
```

**Cross-DAG зависимости**

Можно создавать зависимости между задачами разных DAG через ExternalTaskSensor.

### Параметризация DAG

DAG можно параметризовать для переиспользования.

**Через Airflow Variables**

```python
from airflow.models import Variable

source_table = Variable.get("source_table")
target_bucket = Variable.get("target_bucket")
```

Variables хранятся в Metadata Database и доступны всем DAG.

**Через Jinja-шаблоны**

Airflow поддерживает Jinja-шаблоны в параметрах операторов.

```python
bash_command="echo {{ ds }}"  # ds — execution_date в формате YYYY-MM-DD
```

Доступные переменные в шаблонах:

- `{{ ds }}` — execution_date в формате YYYY-MM-DD;
- `{{ execution_date }}` — полный execution_date;
- `{{ dag }}` — объект DAG;
- `{{ task }}` — объект Task;
- `{{ prev_execution_date }}` — предыдущий execution_date;
- `{{ next_execution_date }}` — следующий execution_date.

**Через конфигурационные файлы**

Можно загружать параметры из YAML или JSON.

```python
import yaml

with open('/config/pipeline_config.yaml') as f:
    config = yaml.safe_load(f)
```

### Динамическая генерация DAG

DAG можно генерировать программно.

Генерация через цикл:

```python
for table in ['users', 'orders', 'products']:
    dag_id = f'load_{table}'
    
    dag = DAG(
        dag_id=dag_id,
        default_args=default_args,
        schedule_interval='@daily',
    )
    
    task = PythonOperator(
        task_id=f'extract_{table}',
        python_callable=extract_function,
        op_args=[table],
        dag=dag,
    )
    
    globals()[dag_id] = dag
```

Это создаёт отдельный DAG для каждой таблицы.

Генерация через конфиг:

```python
tables_config = [
    {'name': 'users', 'schedule': '@daily'},
    {'name': 'orders', 'schedule': '@hourly'},
]

for config in tables_config:
    dag = create_dag(config)
    globals()[dag['dag_id']] = dag
```

### TaskGroups — группировка задач

TaskGroup позволяет группировать связанные задачи визуально и логически.

```python
from airflow.utils.task_group import TaskGroup

with TaskGroup('extract_group') as extract_group:
    task_extract_users = PythonOperator(...)
    task_extract_orders = PythonOperator(...)

with TaskGroup('transform_group') as transform_group:
    task_transform_users = PythonOperator(...)
    task_transform_orders = PythonOperator(...)

extract_group >> transform_group
```

В UI группы отображаются свёрнуто, упрощая восприятие сложных DAG.

### Branching — условное выполнение

BranchPythonOperator позволяет выбирать, какие задачи выполнять в зависимости от условий.

```python
def choose_branch(**context):
    if condition:
        return 'task_a'
    else:
        return 'task_b'

branch_task = BranchPythonOperator(
    task_id='branch',
    python_callable=choose_branch,
    dag=dag,
)

task_a = PythonOperator(...)
task_b = PythonOperator(...)

branch_task >> [task_a, task_b]
```

Невыбранная ветка получает статус `skipped`.

### XCom — обмен данными между задачами

XCom (Cross-Communication) позволяет задачам передавать друг другу данные.

Передача данных:

```python
def task_a(**context):
    result = compute_something()
    context['task_instance'].xcom_push(key='my_key', value=result)
```

Получение данных:

```python
def task_b(**context):
    value = context['task_instance'].xcom_pull(key='my_key', task_ids='task_a')
```

XCom хранится в Metadata Database. Не подходит для больших объёмов данных (размер ограничен).

Для больших данных лучше передавать путь к файлу или ключ в S3, а не сами данные.

## 7. Операторы в Airflow: типы и назначение

Операторы (Operators) — это строительные блоки задач в Airflow. Каждый оператор определяет конкретное действие, которое должно быть выполнено: запуск Python-функции, выполнение SQL-запроса, отправка HTTP-запроса.

### Концепция операторов

Оператор — это шаблон для создания задачи. Он инкапсулирует логику выполнения определённого типа действий.

При создании задачи:

- выбирается подходящий оператор;
- передаются параметры, специфичные для действия;
- оператор создаёт экземпляр задачи в DAG.

Операторы делают код переиспользуемым: одна и та же логика выполнения может применяться в разных DAG с разными параметрами.

### Базовые типы операторов

**Action Operators**

Выполняют действие: запускают код, отправляют запрос, записывают данные.

**Transfer Operators**

Перемещают данные между системами: из БД в S3, из S3 в БД, между БД.

**Sensor Operators**

Ждут выполнения условия: появление файла, доступность API, изменение данных.

### PythonOperator

PythonOperator выполняет Python-функцию.

Базовое использование:

```python
def my_function():
    print("Executing task")
    return "success"

task = PythonOperator(
    task_id='python_task',
    python_callable=my_function,
    dag=dag,
)
```

Передача аргументов в функцию:

```python
def my_function(arg1, arg2):
    print(f"arg1={arg1}, arg2={arg2}")

task = PythonOperator(
    task_id='python_task',
    python_callable=my_function,
    op_args=['value1', 'value2'],  # позиционные аргументы
    op_kwargs={'arg1': 'value1', 'arg2': 'value2'},  # именованные аргументы
    dag=dag,
)
```

Доступ к контексту выполнения:

```python
def my_function(**context):
    execution_date = context['execution_date']
    task_instance = context['task_instance']
    dag_run = context['dag_run']
    
    print(f"Processing data for {execution_date}")

task = PythonOperator(
    task_id='python_task',
    python_callable=my_function,
    provide_context=True,  # в Airflow 2.0+ не требуется, контекст передаётся автоматически
    dag=dag,
)
```

Возвращаемое значение функции автоматически сохраняется в XCom и доступно другим задачам.

### BashOperator

BashOperator выполняет bash-команду.

```python
from airflow.operators.bash import BashOperator

task = BashOperator(
    task_id='bash_task',
    bash_command='echo "Hello from Airflow"',
    dag=dag,
)
```

Выполнение скрипта:

```python
task = BashOperator(
    task_id='run_script',
    bash_command='/scripts/process_data.sh',
    dag=dag,
)
```

Использование Jinja-шаблонов:

```python
task = BashOperator(
    task_id='templated_task',
    bash_command='echo "Processing data for {{ ds }}"',
    dag=dag,
)
```

Передача переменных окружения:

```python
task = BashOperator(
    task_id='bash_with_env',
    bash_command='echo $MY_VAR',
    env={'MY_VAR': 'some_value'},
    dag=dag,
)
```

### PythonVirtualenvOperator

PythonVirtualenvOperator выполняет Python-функцию в изолированном виртуальном окружении с собственными зависимостями.

```python
from airflow.operators.python import PythonVirtualenvOperator

def my_function():
    import pandas as pd
    df = pd.DataFrame({'a': [1, 2, 3]})
    print(df)

task = PythonVirtualenvOperator(
    task_id='virtualenv_task',
    python_callable=my_function,
    requirements=['pandas==1.5.0'],
    system_site_packages=False,
    dag=dag,
)
```

Это полезно когда:

- задаче нужны специфичные версии библиотек;
- задачи требуют конфликтующих зависимостей;
- нужна изоляция от системных пакетов.

### SQL операторы

Airflow предоставляет операторы для работы с различными СУБД.

**PostgresOperator**

```python
from airflow.providers.postgres.operators.postgres import PostgresOperator

task = PostgresOperator(
    task_id='postgres_query',
    postgres_conn_id='postgres_default',
    sql='''
        INSERT INTO staging.users (user_id, name, created_at)
        SELECT user_id, name, created_at
        FROM raw.users
        WHERE load_date = '{{ ds }}'
    ''',
    dag=dag,
)
```

**MySQLOperator**

```python
from airflow.providers.mysql.operators.mysql import MySQLOperator

task = MySQLOperator(
    task_id='mysql_query',
    mysql_conn_id='mysql_default',
    sql='SELECT COUNT(*) FROM users',
    dag=dag,
)
```

**SQLExecuteQueryOperator (универсальный)**

```python
from airflow.providers.common.sql.operators.sql import SQLExecuteQueryOperator

task = SQLExecuteQueryOperator(
    task_id='sql_query',
    conn_id='postgres_default',
    sql='SELECT * FROM users WHERE created_at >= {{ ds }}',
    dag=dag,
)
```

SQL может загружаться из файла:

```python
task = SQLExecuteQueryOperator(
    task_id='sql_from_file',
    conn_id='postgres_default',
    sql='/sql/update_staging.sql',
    dag=dag,
)
```

### Transfer операторы

Transfer операторы перемещают данные между системами.

**S3ToRedshiftOperator**

```python
from airflow.providers.amazon.aws.transfers.s3_to_redshift import S3ToRedshiftOperator

task = S3ToRedshiftOperator(
    task_id='s3_to_redshift',
    s3_bucket='my-bucket',
    s3_key='data/users.parquet',
    schema='staging',
    table='users',
    copy_options=['FORMAT AS PARQUET'],
    dag=dag,
)
```

**PostgresToS3Operator**

```python
from airflow.providers.amazon.aws.transfers.postgres_to_s3 import PostgresToS3Operator

task = PostgresToS3Operator(
    task_id='postgres_to_s3',
    postgres_conn_id='postgres_default',
    query='SELECT * FROM users WHERE created_at >= {{ ds }}',
    s3_bucket='my-bucket',
    s3_key='raw/users/{{ ds }}/data.parquet',
    file_format='parquet',
    dag=dag,
)
```

**MySQLToS3Operator**

Аналогично PostgresToS3Operator, но для MySQL.

### HTTP операторы

**SimpleHttpOperator**

Выполняет HTTP-запрос.

```python
from airflow.providers.http.operators.http import SimpleHttpOperator

task = SimpleHttpOperator(
    task_id='http_request',
    http_conn_id='my_api',
    endpoint='/api/v1/data',
    method='GET',
    headers={'Authorization': 'Bearer token'},
    response_filter=lambda response: response.json(),
    log_response=True,
    dag=dag,
)
```

POST-запрос с данными:

```python
task = SimpleHttpOperator(
    task_id='http_post',
    http_conn_id='my_api',
    endpoint='/api/v1/events',
    method='POST',
    data=json.dumps({'event': 'user_login', 'timestamp': '{{ ts }}'}),
    headers={'Content-Type': 'application/json'},
    dag=dag,
)
```

### Email операторы

**EmailOperator**

Отправляет email.

```python
from airflow.operators.email import EmailOperator

task = EmailOperator(
    task_id='send_email',
    to='team@company.com',
    subject='Daily pipeline completed for {{ ds }}',
    html_content='<p>Pipeline finished successfully</p>',
    dag=dag,
)
```

Отправка с вложениями:

```python
task = EmailOperator(
    task_id='send_report',
    to='stakeholders@company.com',
    subject='Daily report',
    html_content='See attached report',
    files=['/tmp/report_{{ ds }}.csv'],
    dag=dag,
)
```

### Dummy операторы

**DummyOperator / EmptyOperator**

Не выполняет никаких действий. Используется для структурирования DAG.

```python
from airflow.operators.empty import EmptyOperator

start = EmptyOperator(task_id='start', dag=dag)
end = EmptyOperator(task_id='end', dag=dag)

start >> [task_a, task_b, task_c] >> end
```

Это улучшает читаемость графа: явно видны точки начала и конца пайплайна.

### SparkSubmitOperator

Запускает Spark-приложение.

```python
from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator

task = SparkSubmitOperator(
    task_id='spark_job',
    application='/jobs/process_data.py',
    conn_id='spark_default',
    conf={
        'spark.executor.memory': '4g',
        'spark.executor.cores': '2',
    },
    application_args=[
        '--input', 's3://bucket/raw/{{ ds }}',
        '--output', 's3://bucket/staging/{{ ds }}',
    ],
    dag=dag,
)
```

### KubernetesPodOperator

Запускает задачу в Kubernetes pod.

```python
from airflow.providers.cncf.kubernetes.operators.kubernetes_pod import KubernetesPodOperator

task = KubernetesPodOperator(
    task_id='kubernetes_task',
    name='data-processing-pod',
    namespace='airflow',
    image='my-docker-image:latest',
    cmds=['python', '/app/process.py'],
    arguments=['--date', '{{ ds }}'],
    env_vars={'ENV': 'production'},
    dag=dag,
)
```

Это позволяет:

- изолировать задачи в контейнерах;
- использовать разные образы для разных задач;
- масштабировать независимо от Airflow worker;
- контролировать ресурсы на уровне pod.

### DockerOperator

Запускает задачу в Docker-контейнере.

```python
from airflow.providers.docker.operators.docker import DockerOperator

task = DockerOperator(
    task_id='docker_task',
    image='python:3.9',
    command='python -c "print(\'Hello from Docker\')"',
    docker_url='unix://var/run/docker.sock',
    network_mode='bridge',
    dag=dag,
)
```

### BranchPythonOperator

Выбирает следующую задачу на основе условия.

```python
from airflow.operators.python import BranchPythonOperator

def choose_branch(**context):
    execution_date = context['execution_date']
    if execution_date.day == 1:  # первый день месяца
        return 'monthly_task'
    else:
        return 'daily_task'

branch = BranchPythonOperator(
    task_id='branch',
    python_callable=choose_branch,
    dag=dag,
)

monthly_task = PythonOperator(...)
daily_task = PythonOperator(...)

branch >> [monthly_task, daily_task]
```

### ShortCircuitOperator

Останавливает выполнение downstream-задач если условие не выполнено.

```python
from airflow.operators.python import ShortCircuitOperator

def check_condition(**context):
    # Если возвращает False, downstream задачи пропускаются
    return context['execution_date'].weekday() < 5  # только в будни

check = ShortCircuitOperator(
    task_id='check_weekday',
    python_callable=check_condition,
    dag=dag,
)

task_a = PythonOperator(...)
task_b = PythonOperator(...)

check >> task_a >> task_b
```

Если `check_condition` возвращает `False`, `task_a` и `task_b` получают статус `skipped`.

### Кастомные операторы

Можно создавать собственные операторы, наследуясь от BaseOperator.

```python
from airflow.models.baseoperator import BaseOperator

class CustomOperator(BaseOperator):
    def __init__(self, my_param, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.my_param = my_param
    
    def execute(self, context):
        # Основная логика выполнения
        self.log.info(f"Executing with param: {self.my_param}")
        result = self.process_data()
        return result
    
    def process_data(self):
        # Ваша логика обработки
        pass
```

Использование:

```python
task = CustomOperator(
    task_id='custom_task',
    my_param='value',
    dag=dag,
)
```

### Параметры операторов общего назначения

Все операторы поддерживают общие параметры:

**task_id**

Уникальный идентификатор задачи в рамках DAG.

**retries**

Количество автоматических повторов при ошибке.

**retry_delay**

Задержка между повторами (timedelta).

**execution_timeout**

Максимальное время выполнения задачи. Если превышено — задача убивается.

**depends_on_past**

Если `True`, задача выполняется только если аналогичная задача в предыдущем DagRun завершилась успешно.

**wait_for_downstream**

Если `True`, задача ждёт завершения всех downstream-задач в предыдущем DagRun.

**trigger_rule**

Правило, определяющее когда задача запускается:

- `all_success` (по умолчанию) — все upstream-задачи успешны;
- `all_failed` — все upstream-задачи упали;
- `all_done` — все upstream-задачи завершились (успешно или нет);
- `one_success` — хотя бы одна upstream-задача успешна;
- `one_failed` — хотя бы одна upstream-задача упала;
- `none_failed` — ни одна upstream-задача не упала (успех или пропуск);
- `none_skipped` — ни одна upstream-задача не пропущена.

**pool**

Имя пула ресурсов, к которому относится задача. Пулы ограничивают количество одновременно выполняющихся задач определённого типа.

**priority_weight**

Приоритет задачи. Задачи с большим приоритетом выполняются раньше при наличии очереди.

**queue**

Очередь для Celery Executor. Позволяет направлять задачи на определённые worker-ноды.

**on_failure_callback**

Функция, вызываемая при падении задачи.

```python
def failure_handler(context):
    task_instance = context['task_instance']
    send_alert(f"Task {task_instance.task_id} failed")

task = PythonOperator(
    task_id='my_task',
    python_callable=my_function,
    on_failure_callback=failure_handler,
    dag=dag,
)
```

**on_success_callback**

Функция, вызываемая при успешном завершении задачи.

**on_retry_callback**

Функция, вызываемая при повторе задачи после ошибки.

---

## 8. Сенсоры в Airflow: ожидание условий

Сенсоры (Sensors) — специальный тип операторов, которые ждут выполнения определённого условия перед продолжением выполнения пайплайна.

### Концепция сенсоров

Сенсор периодически проверяет условие:

- если условие выполнено — задача завершается со статусом `success`;
- если условие не выполнено — сенсор ждёт и проверяет снова;
- если таймаут истёк — задача завершается со статусом `failed`.

Сенсоры нужны когда выполнение задачи зависит от внешнего события:

- появление файла в хранилище;
- завершение внешней задачи;
- изменение данных в БД;
- доступность API.

### Режимы работы сенсоров

**Poke mode (по умолчанию)**

Сенсор занимает worker-слот и периодически проверяет условие. Между проверками worker ждёт (sleep).

Преимущества:

- простая реализация;
- мгновенная реакция на выполнение условия.

Недостатки:

- занимает worker-слот всё время ожидания;
- при большом количестве сенсоров может исчерпаться пул worker.

**Reschedule mode**

Сенсор освобождает worker-слот между проверками. Между проверками задача переводится в состояние `up_for_reschedule`.

Преимущества:

- не занимает worker-слот во время ожидания;
- позволяет запускать больше сенсоров одновременно.

Недостатки:

- между проверками задача проходит через scheduler;
- возможна небольшая задержка в реакции.

Выбор режима:

```python
sensor = FileSensor(
    task_id='wait_for_file',
    filepath='/data/file.csv',
    mode='reschedule',  # или 'poke'
    dag=dag,
)
```

### Параметры сенсоров

**poke_interval**

Интервал между проверками условия (в секундах). По умолчанию 60 секунд.

```python
sensor = FileSensor(
    task_id='wait_for_file',
    filepath='/data/file.csv',
    poke_interval=30,  # проверять каждые 30 секунд
    dag=dag,
)
```

**timeout**

Максимальное время ожидания условия (в секундах). По умолчанию 7 дней.

```python
sensor = FileSensor(
    task_id='wait_for_file',
    filepath='/data/file.csv',
    timeout=3600,  # ждать максимум 1 час
    dag=dag,
)
```

**soft_fail**

Если `True`, при таймауте задача получает статус `skipped` вместо `failed`. Это позволяет продолжить выполнение downstream-задач.

```python
sensor = FileSensor(
    task_id='wait_for_file',
    filepath='/data/file.csv',
    soft_fail=True,
    dag=dag,
)
```

### FileSensor

Ждёт появления файла в файловой системе.

```python
from airflow.sensors.filesystem import FileSensor

sensor = FileSensor(
    task_id='wait_for_file',
    filepath='/data/input_{{ ds }}.csv',
    fs_conn_id='fs_default',
    poke_interval=30,
    dag=dag,
)
```

### S3KeySensor

Ждёт появления объекта в S3.

```python
from airflow.providers.amazon.aws.sensors.s3 import S3KeySensor

sensor = S3KeySensor(
    task_id='wait_for_s3_file',
    bucket_name='my-bucket',
    bucket_key='raw/users/{{ ds }}/data.parquet',
    aws_conn_id='aws_default',
    timeout=3600,
    poke_interval=60,
    dag=dag,
)
```

Проверка наличия файлов по маске:

```python
sensor = S3KeySensor(
    task_id='wait_for_s3_files',
    bucket_name='my-bucket',
    bucket_key='raw/users/{{ ds }}/*.parquet',
    wildcard_match=True,
    dag=dag,
)
```

### SqlSensor

Ждёт выполнения SQL-условия.

```python
from airflow.providers.common.sql.sensors.sql import SqlSensor

sensor = SqlSensor(
    task_id='wait_for_data',
    conn_id='postgres_default',
    sql='''
        SELECT COUNT(*) 
        FROM raw.events 
        WHERE event_date = '{{ ds }}' 
        AND processed = false
    ''',
    success=lambda result: result[0][0] > 0,  # условие успеха
    poke_interval=60,
    dag=dag,
)
```

Условие считается выполненным, если SQL-запрос возвращает не-пустой результат или результат соответствует функции `success`.

### HttpSensor

Ждёт определённого ответа от HTTP-эндпоинта.

```python
from airflow.providers.http.sensors.http import HttpSensor

sensor = HttpSensor(
    task_id='wait_for_api',
    http_conn_id='my_api',
    endpoint='/api/v1/status',
    request_params={'date': '{{ ds }}'},
    response_check=lambda response: response.json()['status'] == 'ready',
    poke_interval=30,
    dag=dag,
)
```

### ExternalTaskSensor

Ждёт завершения задачи в другом DAG.

```python
from airflow.sensors.external_task import ExternalTaskSensor

sensor = ExternalTaskSensor(
    task_id='wait_for_upstream_dag',
    external_dag_id='upstream_pipeline',
    external_task_id='final_task',
    execution_delta=timedelta(hours=1),  # смещение execution_date
    poke_interval=60,
    dag=dag,
)
```

`execution_delta` нужен когда upstream DAG запускается раньше текущего DAG. Например, upstream DAG запускается в 01:00, текущий в 02:00 — `execution_delta = timedelta(hours=1)`.

### TimeSensor / TimeDeltaSensor

Ждёт определённого времени суток.

```python
from airflow.sensors.time_sensor import TimeSensor

sensor = TimeSensor(
    task_id='wait_until_10am',
    target_time=time(10, 0, 0),  # 10:00:00
    dag=dag,
)
```

TimeDeltaSensor ждёт определённое время с начала execution_date:

```python
from airflow.sensors.time_delta import TimeDeltaSensor

sensor = TimeDeltaSensor(
    task_id='wait_2_hours',
    delta=timedelta(hours=2),
    dag=dag,
)
```

### PythonSensor

Ждёт выполнения произвольного Python-условия.

```python
from airflow.sensors.python import PythonSensor

def check_condition(**context):
    # Возвращает True если условие выполнено, False иначе
    import random
    return random.random() > 0.5

sensor = PythonSensor(
    task_id='wait_for_condition',
    python_callable=check_condition,
    poke_interval=30,
    dag=dag,
)
```

Это универсальный сенсор для любых кастомных условий.

### DateTimeSensor

Ждёт определённой даты и времени.

```python
from airflow.sensors.date_time import DateTimeSensor

sensor = DateTimeSensor(
    task_id='wait_until_date',
    target_time='{{ macros.datetime.strptime(ds, "%Y-%m-%d") + macros.timedelta(days=1, hours=2) }}',
    dag=dag,
)
```

### Кастомные сенсоры

Можно создавать собственные сенсоры, наследуясь от BaseSensorOperator.

```python
from airflow.sensors.base import BaseSensorOperator

class CustomSensor(BaseSensorOperator):
    def __init__(self, my_param, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.my_param = my_param
    
    def poke(self, context):
        # Логика проверки условия
        # Возвращает True если условие выполнено, False иначе
        condition_met = self.check_condition()
        return condition_met
    
    def check_condition(self):
        # Ваша логика
        pass
```

### Паттерны использования сенсоров

**Ожидание данных из источника**

```python
wait_for_source = S3KeySensor(
    task_id='wait_for_source_data',
    bucket_name='source-bucket',
    bucket_key='exports/{{ ds }}/data.csv',
)

extract_data = PythonOperator(...)

wait_for_source >> extract_data
```

**Ожидание завершения upstream-пайплайна**

```python
wait_for_upstream = ExternalTaskSensor(
    task_id='wait_for_extraction',
    external_dag_id='data_extraction_pipeline',
    external_task_id='load_to_s3',
)

transform_data = PythonOperator(...)

wait_for_upstream >> transform_data
```

**Ожидание доступности внешней системы**

```python
wait_for_api = HttpSensor(
    task_id='wait_for_api_available',
    http_conn_id='external_api',
    endpoint='/health',
)

call_api = SimpleHttpOperator(...)

wait_for_api >> call_api
```

**Координация между параллельными пайплайнами**

```python
wait_for_pipeline_a = ExternalTaskSensor(
    task_id='wait_for_pipeline_a',
    external_dag_id='pipeline_a',
    external_task_id='final_task',
)

wait_for_pipeline_b = ExternalTaskSensor(
    task_id='wait_for_pipeline_b',
    external_dag_id='pipeline_b',
    external_task_id='final_task',
)

merge_data = PythonOperator(...)

[wait_for_pipeline_a, wait_for_pipeline_b] >> merge_data
```

## 9. Streaming Ingestion: концепция и применение

Streaming ingestion — это непрерывная загрузка данных в аналитическую платформу по мере их появления в источнике. В отличие от batch, где данные накапливаются и загружаются порциями, streaming обрабатывает данные как бесконечный поток событий.

### Природа потоковых данных

Потоковые данные генерируются непрерывно и имеют фундаментально другую природу по сравнению с batch-данными.

В batch мы работаем с конечными наборами данных: есть начало, есть конец, можно посчитать размер, можно обработать дважды, можно гарантировать полноту.

В streaming мы работаем с бесконечными потоками: нет конца потока, размер заранее неизвестен, каждое событие обрабатывается один раз при прохождении, полнота определяется временными окнами.

Поток событий — это последовательность записей, приходящих во времени. Каждое событие имеет timestamp и payload с данными. События могут приходить с разной интенсивностью: иногда тысячи в секунду, иногда единицы.

### Когда нужен streaming

Streaming необходим когда критична актуальность данных и когда объёмы данных делают batch-загрузку неэффективной.

Реальные сценарии использования:

События из мобильных приложений генерируются постоянно. Пользователи открывают приложение, кликают, совершают действия. Эти события нужны для реальной аналитики поведения, для триггеров маркетинговых кампаний, для обнаружения аномалий.

Клики на сайте и действия пользователей в веб-приложениях. Данные о каждом клике, просмотре страницы, действии на сайте. Эти данные нужны для персонализации контента, для A/B тестов, для понимания user journey в реальном времени.

Логи серверов и приложений генерируются непрерывно. Каждый запрос к API, каждая ошибка, каждое изменение состояния системы логируется. Эти данные нужны для мониторинга, для обнаружения проблем, для анализа производительности.

Данные с IoT-устройств приходят постоянно: датчики, трекеры, устройства мониторинга. Данные о температуре, местоположении, состоянии оборудования. Нужны для оперативного реагирования, для предсказания отказов, для оптимизации процессов.

Транзакции в платёжных системах происходят в реальном времени. Каждый платёж, каждое изменение баланса. Данные нужны для фрод-детекта, для мониторинга финансовых метрик, для соблюдения регуляторных требований.

### Event-driven архитектура

Streaming ingestion является частью event-driven архитектуры. В такой архитектуре системы общаются через события, а не через прямые вызовы.

Источник генерирует событие и публикует его в поток. Источник не знает, кто будет обрабатывать событие. Это может быть одна система или десять систем одновременно.

Потребители подписываются на поток событий и обрабатывают их независимо друг от друга. Один потребитель может писать события в хранилище, другой — считать метрики в реальном времени, третий — отправлять уведомления.

Такая архитектура даёт слабую связанность систем: источник и потребители не зависят друг от друга. Можно добавлять новых потребителей без изменения источника. Можно менять логику обработки без изменения источника.

### Задержка в streaming системах

Streaming не означает мгновенность. Есть задержка между моментом генерации события и моментом его появления в аналитической системе.

Задержка складывается из нескольких компонентов:

Время доставки события от источника в поток. Зависит от сети, от батчинга на стороне источника, от настроек producer.

Время нахождения события в очереди. Если поток перегружен или потребитель медленный, события накапливаются в очереди.

Время обработки события потребителем. Зависит от сложности логики обработки, от производительности потребителя.

Время записи результата в целевое хранилище. Зависит от скорости записи в хранилище, от батчинга при записи.

В хорошо настроенной streaming системе end-to-end задержка составляет секунды или десятки секунд. Это называется near real-time, а не строго real-time.

### Обработка событий с опозданием

События могут приходить с опозданием. Событие могло быть сгенерировано час назад, но попасть в поток только сейчас из-за проблем с сетью или из-за того, что мобильное устройство было оффлайн.

В streaming системах различают event time и processing time:

Event time — время когда событие реально произошло. Это timestamp, который приходит вместе с событием от источника.

Processing time — время когда событие было обработано в streaming системе. Это timestamp момента обработки.

Разница между ними называется event time skew. Эта разница может быть значительной.

Для корректной обработки событий с опозданием используются временные окна с watermarks. Watermark — это метка времени, которая говорит "все события до этого момента уже пришли". События, пришедшие после watermark, считаются опоздавшими.

Опоздавшие события можно обрабатывать по-разному: отбрасывать, обрабатывать отдельно, пересчитывать уже закрытые окна.

### Windowing — обработка по временным окнам

В streaming невозможно обработать весь поток целиком — он бесконечный. Поэтому поток разбивается на временные окна.

Tumbling windows — последовательные непересекающиеся окна фиксированного размера. Окно 5 минут означает: 00:00-00:05, 00:05-00:10, 00:10-00:15 и так далее. Каждое событие попадает ровно в одно окно.

Sliding windows — скользящие окна фиксированного размера с определённым шагом. Окно 10 минут с шагом 5 минут означает: 00:00-00:10, 00:05-00:15, 00:10-00:20. События могут попадать в несколько окон одновременно.

Session windows — окна переменного размера, определяемые активностью пользователя. Окно начинается с первого события и закрывается после периода неактивности. Используется для анализа сессий пользователей.

По каждому окну можно считать агрегаты: количество событий, сумму значений, среднее, максимум, минимум. Результат агрегата доступен после закрытия окна.

### Guarantees — гарантии обработки

В streaming системах важны гарантии обработки событий. Существует три уровня гарантий:

At-most-once — событие обрабатывается максимум один раз. Может быть потеряно при сбое. Самая быстрая обработка, но с риском потери данных. Подходит для некритичных данных.

At-least-once — событие обрабатывается минимум один раз. При сбое может быть обработано повторно, что приводит к дубликатам. Гарантирует отсутствие потерь, но требует идемпотентности обработки.

Exactly-once — событие обрабатывается ровно один раз. Самая сильная гарантия, но самая дорогая в реализации. Требует координации между компонентами системы через транзакции или распределённые снапшоты.

Выбор уровня гарантий зависит от требований бизнеса. Для метрик показов рекламы нужен exactly-once, чтобы не переплачивать. Для логов мониторинга достаточно at-least-once.

### Backpressure и flow control

Когда источник генерирует события быстрее, чем потребитель может их обработать, возникает backpressure — давление со стороны необработанных данных.

Без механизмов контроля backpressure приводит к переполнению очередей, к росту задержек, к падению системы из-за нехватки памяти.

Механизмы управления backpressure:

Буферизация событий в очереди. Очередь накапливает события, сглаживая всплески нагрузки. Но размер очереди ограничен.

Отбрасывание событий при переполнении. Старые события удаляются, освобождая место новым. Подходит для некритичных данных.

Throttling источника. Источнику сигнализируют замедлиться. Источник снижает скорость генерации событий.

Горизонтальное масштабирование потребителей. Добавление новых потребителей увеличивает пропускную способность обработки.

### Stateful обработка в streaming

Некоторые задачи требуют сохранения состояния между событиями. Подсчёт количества событий по ключу, вычисление скользящих средних, джойны потоков требуют state.

State — это данные, которые накапливаются в процессе обработки потока. State может быть локальным в памяти потребителя или распределённым в внешнем хранилище.

Локальный state быстрый, но теряется при падении потребителя. Для восстановления state после сбоя используется checkpointing — периодическое сохранение снапшота state в надёжное хранилище.

При перезапуске потребителя state восстанавливается из последнего checkpoint. Обработка продолжается с места остановки.

Управление state усложняет streaming систему, но необходимо для многих аналитических задач.

---

## 10. Apache Kafka: архитектура и компоненты

Apache Kafka — это распределённая платформа потоковой передачи данных. Kafka стала де-факто стандартом для построения streaming систем в data-инженерии.

### Зачем нужна Kafka

До появления Kafka передача данных между системами выглядела как point-to-point интеграции. Каждая система напрямую общалась с каждой другой системой. При добавлении новой системы нужно было создавать интеграции со всеми существующими.

Количество интеграций росло квадратично: N систем требуют N×(N-1)/2 интеграций. Это становилось неуправляемым.

Kafka решает эту проблему, выступая центральным хабом для передачи данных. Системы публикуют данные в Kafka и читают данные из Kafka. Каждая система интегрируется только с Kafka, а не со всеми остальными системами.

Количество интеграций становится линейным: N систем требуют N интеграций с Kafka.

### Основная идея Kafka

Kafka — это распределённый лог. Лог — это упорядоченная последовательность записей, где каждая новая запись добавляется в конец.

Записи в Kafka называются сообщениями или событиями. Каждое сообщение имеет ключ, значение и timestamp. Сообщения неизменяемы — после записи в лог их нельзя изменить или удалить.

Kafka хранит сообщения на диске, а не только в памяти. Это делает Kafka надёжной: сообщения не теряются при перезапуске. Это также позволяет хранить большие объёмы данных дешевле, чем в памяти.

Kafka организует сообщения в topics. Topic — это именованная категория сообщений. Можно представить topic как таблицу в БД или папку в файловой системе. Все сообщения одной категории идут в один topic.

### Архитектура Kafka: компоненты

Kafka состоит из нескольких ключевых компонентов, которые взаимодействуют друг с другом.

**Broker**

Broker — это сервер Kafka. Один broker — это один процесс Kafka, запущенный на одной машине. Broker хранит данные на локальном диске и обслуживает запросы от producers и consumers.

Kafka работает как кластер из нескольких brokers. Типичный production кластер содержит минимум 3 broker, часто больше. Brokers координируются друг с другом, распределяют данные, реплицируют для надёжности.

**Producer**

Producer — это приложение, которое публикует сообщения в Kafka. Producer подключается к кластеру Kafka и отправляет сообщения в нужный topic.

Producer определяет, в какую партицию topic отправить сообщение. Это делается на основе ключа сообщения или round-robin при отсутствии ключа.

Producer может работать в разных режимах: синхронно ждать подтверждения записи или отправлять асинхронно без ожидания. Выбор режима определяет balance между throughput и надёжностью.

**Consumer**

Consumer — это приложение, которое читает сообщения из Kafka. Consumer подписывается на один или несколько topics и получает сообщения по мере их появления.

Consumers объединяются в consumer groups. Все consumers в одной группе читают разные партиции одного topic, распределяя нагрузку. Если один consumer падает, его партиции перераспределяются на оставшихся.

Consumer отслеживает offset — позицию в логе до которой он прочитал сообщения. Offset сохраняется в специальном служебном topic. Это позволяет consumer продолжить чтение с места остановки после перезапуска.

**ZooKeeper (в старых версиях)**

ZooKeeper использовался для координации Kafka кластера: хранения метаданных, выбора leader для партиций, мониторинга состояния brokers.

Начиная с Kafka 3.x ZooKeeper больше не нужен. Kafka перешла на собственный протокол координации KRaft. Это упрощает развёртывание и улучшает масштабируемость.

### Как работает запись в Kafka

Producer отправляет сообщение в Kafka. Сообщение содержит topic, ключ (опционально), значение и timestamp.

Kafka определяет, в какую партицию topic записать сообщение. Если есть ключ, используется hash от ключа для выбора партиции. Это гарантирует, что сообщения с одинаковым ключом попадут в одну партицию и сохранят порядок.

Сообщение записывается в leader партиции. Leader — это broker, ответственный за конкретную партицию. Leader записывает сообщение на диск.

Leader реплицирует сообщение на follower brokers. Follower — это brokers, которые хранят копии партиции для надёжности. Количество реплик настраивается параметром replication factor.

После успешной репликации на минимальное количество followers (in-sync replicas), leader отправляет producer подтверждение записи.

Producer получает подтверждение и может считать сообщение успешно записанным.

### Как работает чтение из Kafka

Consumer подписывается на topic. Consumer указывает, с какого offset начинать чтение: с начала topic, с конца, с конкретной позиции, с последней сохранённой позиции.

Consumer запрашивает сообщения у leader партиции. Leader возвращает batch сообщений, начиная с запрошенного offset.

Consumer обрабатывает полученные сообщения. Обработка происходит на стороне consumer — Kafka только доставляет сообщения.

Consumer фиксирует offset обработанных сообщений. Это называется commit offset. Committed offset сохраняется в Kafka и используется при перезапуске consumer.

Consumer запрашивает следующий batch сообщений, и цикл повторяется.

### Offset и гарантии доставки

Offset — это позиция сообщения в партиции. Это просто число: первое сообщение имеет offset 0, второе — 1, и так далее. Offset уникален в рамках партиции, но не уникален между партициями.

Consumer использует offset для отслеживания прогресса чтения. Committed offset показывает, до какого сообщения consumer обработал данные.

Момент commit offset определяет guarantees доставки:

Commit до обработки сообщения даёт at-most-once. Если consumer падает после commit но до обработки, сообщение теряется.

Commit после обработки сообщения даёт at-least-once. Если consumer падает после обработки но до commit, сообщение обрабатывается повторно.

Exactly-once достигается через транзакции Kafka. Consumer и producer координируются через транзакционные commit, гарантируя обработку ровно один раз.

### Retention — хранение данных в Kafka

Kafka хранит сообщения в течение настраиваемого периода retention. После истечения retention сообщения удаляются для освобождения места.

Retention может быть настроен по времени или по размеру:

Time-based retention: хранить сообщения 7 дней, после чего удалять. Подходит для большинства случаев.

Size-based retention: хранить максимум 100 GB данных в партиции, удаляя старые сообщения при превышении. Подходит когда место ограничено.

Retention позволяет consumer читать старые данные. Consumer может вернуться к любому offset в рамках retention периода и перечитать данные. Это полезно для пересчётов, для отладки, для новых consumers.

Некоторые topics настраивают с бесконечным retention. Это превращает Kafka в долговременное хранилище событий, своего рода event store.

### Log compaction

Log compaction — это альтернативный режим retention. Вместо удаления старых сообщений по времени, Kafka сохраняет только последнее сообщение для каждого ключа.

Это полезно для topics, которые хранят состояние: текущий статус заказа, текущий профиль пользователя. Не нужна вся история изменений, нужно только актуальное состояние.

Log compaction работает в фоне. Kafka периодически сканирует партицию, находит дубликаты ключей и удаляет старые версии, сохраняя только последнюю.

Consumer читая compacted topic получает полную картину текущего состояния всех ключей, даже если подписался недавно.

---

## 11. Topics, Partitions, Replication в Kafka

Topics и partitions — основные абстракции организации данных в Kafka. Понимание их устройства критично для правильного проектирования Kafka-систем.

### Topic — категория сообщений

Topic в Kafka — это именованный поток сообщений. Все сообщения одного типа публикуются в один topic. Topics логически разделяют разные типы данных.

Имена topics должны быть осмысленными и отражать содержание. Хорошие имена: `user.events`, `orders.created`, `payments.processed`. Плохие имена: `topic1`, `data`, `stream`.

Topic не имеет фиксированной схемы на уровне Kafka. Kafka не знает и не проверяет структуру сообщений. Producer может отправлять в topic любые данные. Но на практике все producers обычно отправляют данные одной структуры.

Для управления схемами используются внешние инструменты: Schema Registry. Это отдельный сервис, который хранит схемы сообщений и валидирует их при записи и чтении.

Topics создаются автоматически при первой записи или явно через CLI/API с нужными параметрами. Рекомендуется создавать topics явно, чтобы контролировать количество партиций и replication factor.

### Partition — единица параллелизма

Каждый topic разделён на partitions. Partition — это упорядоченный лог, часть topic. Topic может иметь одну партицию или тысячи партиций.

Partitions позволяют распараллелить обработку данных. Разные partitions обрабатываются независимо разными consumers. Чем больше партиций, тем выше потенциальный параллелизм.

Сообщения внутри одной партиции строго упорядочены. Если сообщение A записано в партицию раньше сообщения B, то A всегда будет прочитано раньше B.

Между партициями порядок не гарантируется. Сообщения из разных партиций могут быть прочитаны в любом порядке.

Партиции распределены по brokers кластера. Каждая партиция целиком хранится на одном broker (с репликами на других brokers). Это позволяет балансировать нагрузку и данные между машинами.

### Выбор количества партиций

Количество партиций в topic — критичный параметр. Его сложно изменить после создания topic.

Слишком мало партиций ограничивает параллелизм. Если у topic одна партиция, только один consumer в группе может её читать. Throughput ограничен производительностью одного consumer.

Слишком много партиций создаёт overhead. Каждая партиция требует памяти и файловых дескрипторов на broker. Kafka хуже работает с десятками тысяч партиций.

Практические рекомендации:

Начать с количества партиций равного ожидаемому количеству consumers. Если планируется 10 параллельных consumers, создать 10 партиций.

Учитывать throughput: каждая партиция может пропускать 10-100 MB/s. Если нужен throughput 1 GB/s, нужно минимум 10-100 партиций.

Планировать рост: увеличить количество партиций потом сложно. Лучше создать с запасом.

Не делать тысячи партиций без необходимости. 10-100 партиций — разумный диапазон для большинства use cases.

### Partitioning — распределение сообщений по партициям

Когда producer отправляет сообщение в topic, Kafka должен выбрать, в какую партицию его записать. Это называется partitioning.

Стратегии partitioning:

**По ключу сообщения**

Если сообщение имеет ключ, используется hash(key) % num_partitions для выбора партиции. Это гарантирует, что все сообщения с одинаковым ключом попадут в одну партицию.

Это критично для задач, требующих порядка обработки по ключу. Например, все события одного пользователя должны обрабатываться в порядке, поэтому user_id используется как ключ.

**Round-robin**

Если ключ отсутствует, сообщения распределяются равномерно по партициям по очереди. Это обеспечивает равномерную нагрузку.

**Кастомный partitioner**

Producer может реализовать свою логику выбора партиции. Например, все сообщения из одного региона направлять в одни партиции, из другого региона — в другие.

Выбор ключа partitioning влияет на:

- порядок обработки сообщений;
- балансировку нагрузки между партициями;
- возможность scale consumers.

### Replication — надёжность через копии

Kafka реплицирует данные для надёжности. Каждая партиция имеет несколько реплик на разных brokers.

Replication factor определяет количество реплик. Обычно используется replication factor 3: одна leader replica и две follower replicas.

Leader replica обрабатывает все запросы чтения и записи для партиции. Leader активно работает, followers пассивно реплицируют данные.

Follower replicas копируют данные с leader. Followers не обслуживают запросы клиентов, их единственная задача — хранить копию данных.

Если broker с leader падает, один из followers автоматически становится новым leader. Это называется leader election. Переключение происходит автоматически за секунды.

Клиенты автоматически переключаются на нового leader. Producer и consumer получают информацию о новом leader из метаданных кластера и переподключаются.

### In-Sync Replicas (ISR)

Не все followers равны. Follower считается in-sync, если он успевает реплицировать данные с leader с минимальной задержкой.

In-Sync Replicas (ISR) — это набор реплик, которые полностью синхронизированы с leader. ISR всегда включает leader и часть followers.

Follower может выпасть из ISR если:

- отстал от leader на настроенное количество сообщений;
- не отправлял fetch запросы в течение настроенного времени;
- broker с follower недоступен.

Producer может требовать подтверждения записи от определённого количества ISR. Параметр `acks` контролирует это:

`acks=0` — producer не ждёт подтверждения. Максимальный throughput, но данные могут быть потеряны.

`acks=1` — producer ждёт подтверждения от leader. Данные записаны, но могут быть потеряны при падении leader до репликации.

`acks=all` — producer ждёт подтверждения от всех ISR. Максимальная надёжность, но меньший throughput.

Для критичных данных используется `acks=all` с `min.insync.replicas=2`. Это гарантирует, что данные записаны минимум на два broker перед подтверждением.

### Leader election и доступность

Когда broker с leader партиции падает, Kafka автоматически выбирает нового leader из ISR.

Критерий выбора: follower из ISR с наибольшим offset становится leader. Это гарантирует минимальную потерю данных.

Если все ISR недоступны, Kafka может выбрать leader из не-ISR followers. Это называется unclean leader election. Включается параметром `unclean.leader.election.enable`.

Unclean election восстанавливает доступность ценой возможной потери данных. Follower вне ISR может не иметь последних сообщений.

Выбор между доступностью и консистентностью зависит от требований. Для финансовых данных unclean election отключают. Для логов мониторинга можно включить.

### Распределение партиций по brokers

Kafka автоматически распределяет партиции и реплики по brokers кластера для балансировки нагрузки и надёжности.

Принципы распределения:

Leaders партиций равномерно распределены по brokers. Это балансирует write нагрузку.

Replicas партиции размещены на разных brokers. Никогда две реплики одной партиции не находятся на одном broker.

Если brokers находятся в разных rack или availability zones, Kafka учитывает это. Replicas распределяются по разным zones для защиты от сбоев целой зоны.

При добавлении новых brokers в кластер партиции не перемещаются автоматически. Нужно запустить rebalance партиций вручную. Это предотвращает неожиданную нагрузку на кластер.

---

## 12. Producers и Consumers в Kafka

Producers и consumers — это клиенты Kafka, которые пишут и читают данные. Понимание их работы критично для построения надёжных streaming систем.

### Producer — публикация сообщений

Producer — это приложение, которое отправляет сообщения в Kafka. Producer может быть написан на любом языке: Java, Python, Go, C++. Kafka предоставляет клиентские библиотеки для всех популярных языков.

Producer подключается к Kafka кластеру, получает метаданные о topics и partitions, затем отправляет сообщения в нужные партиции.

Producer работает асинхронно. Сообщения накапливаются в буфере в памяти, затем отправляются batches на brokers. Это увеличивает throughput: отправка batch эффективнее, чем отправка каждого сообщения отдельно.

Размер batch и время накопления настраиваются. Больший batch увеличивает throughput, но увеличивает latency. Меньший batch снижает latency, но снижает throughput.

### Ключевые параметры Producer

Producer имеет множество параметров настройки, влияющих на производительность и надёжность.

**acks** — уровень подтверждения записи. Определяет, сколько реплик должны подтвердить запись перед возвратом успеха producer.

**batch.size** — максимальный размер batch в байтах. Больший размер увеличивает throughput.

**linger.ms** — время ожидания перед отправкой batch. Даже если batch не заполнен, он отправляется после истечения этого времени.

**compression.type** — алгоритм сжатия сообщений. Поддерживается gzip, snappy, lz4, zstd. Сжатие уменьшает размер передаваемых данных и размер на диске.

**buffer.memory** — размер буфера в памяти для накопления сообщений. Если буфер заполнен, producer блокируется или отбрасывает сообщения.

**retries** — количество повторных попыток при ошибке отправки. Producer автоматически повторяет отправку при временных сбоях сети.

**max.in.flight.requests.per.connection** — количество неподтверждённых запросов на одно соединение. Влияет на порядок сообщений при ретраях.

### Idempotent Producer

При ретраях одно и то же сообщение может быть отправлено несколько раз. Это создаёт дубликаты в Kafka.

Idempotent producer решает эту проблему. Каждому сообщению присваивается уникальный sequence number. Kafka отслеживает эти номера и отбрасывает дубликаты.

Включается параметром `enable.idempotence=true`. Это автоматически настраивает другие параметры для обеспечения exactly-once семантики на уровне producer.

Idempotent producer гарантирует отсутствие дубликатов в рамках одной producer сессии. Это не даёт полного exactly-once между producer и consumer, но решает проблему дубликатов при ретраях.

### Transactional Producer

Transactional producer позволяет атомарно записать сообщения в несколько topics и commit consumer offset в одной транзакции.

Это нужно для exactly-once обработки в сценариях read-process-write: consumer читает из topic A, обрабатывает, пишет в topic B, commit offset topic A. Все эти операции должны произойти атомарно.

Transactional producer требует уникального transactional.id. Producer с одним transactional.id может иметь только одну активную транзакцию.

Транзакции увеличивают latency и снижают throughput, но дают сильные гарантии консистентности.

### Consumer — чтение сообщений

Consumer — это приложение, которое читает сообщения из Kafka. Consumer подписывается на один или несколько topics и получает сообщения.

Consumer работает в pull модели: consumer запрашивает сообщения у broker, broker возвращает batch. Это отличается от push модели, где broker активно отправляет сообщения.

Pull модель даёт consumer контроль над скоростью потребления. Consumer обрабатывает сообщения со своей скоростью, не перегружаясь.

Consumer отслеживает offset — позицию до которой он прочитал партицию. Offset хранится в специальном служебном topic `__consumer_offsets`.

### Consumer Groups

Consumers объединяются в consumer groups. Все consumers в одной группе совместно читают партиции topics.

Каждая партиция назначается только одному consumer в группе. Это гарантирует, что сообщения из одной партиции обрабатываются по порядку одним consumer.

Если consumers в группе меньше, чем партиций, один consumer читает несколько партиций. Если consumers больше, чем партиций, лишние consumers простаивают.

Consumer group позволяет горизонтально масштабировать обработку. Добавление новых consumers в группу увеличивает параллелизм обработки.

Разные consumer groups читают один topic независимо. Каждая группа отслеживает свой offset. Это позволяет иметь несколько приложений, обрабатывающих один поток данных по-разному.

### Rebalancing — перераспределение партиций

Когда consumer присоединяется к группе или покидает её, происходит rebalancing — перераспределение партиций между consumers.

Rebalancing гарантирует, что все партиции обрабатываются и нагрузка распределена равномерно.

Во время rebalancing обработка сообщений останавливается. Все consumers в группе останавливают чтение, ждут завершения rebalancing, получают новое назначение партиций, возобновляют чтение.

Частые rebalancing негативно влияют на производительность. Consumer group становится нестабильной, throughput падает.

Причины частых rebalancing:

- consumers падают и перезапускаются;
- обработка сообщений слишком медленная, session timeout истекает;
- сетевые проблемы между consumer и broker.

Для стабильности нужно настроить параметры session.timeout.ms и max.poll.interval.ms под реальное время обработки.

### Ключевые параметры Consumer

**group.id** — идентификатор consumer group. Consumers с одним group.id формируют одну группу.

**auto.offset.reset** — поведение при отсутствии сохранённого offset. `earliest` начинает с начала topic, `latest` — с конца.

**enable.auto.commit** — автоматический commit offset. Если true, offset коммитится автоматически через auto.commit.interval.ms.

**max.poll.records** — максимальное количество сообщений, возвращаемых за один poll.

**session.timeout.ms** — время, через которое consumer считается мёртвым, если не отправляет heartbeat.

**max.poll.interval.ms** — максимальное время между вызовами poll. Если превышено, consumer считается мёртвым.

**fetch.min.bytes** — минимальный размер данных для возврата. Broker ждёт накопления минимального размера перед ответом.

**fetch.max.wait.ms** — максимальное время ожидания данных. Если данных меньше fetch.min.bytes, broker ждёт максимум это время.

### Commit Offset стратегии

Commit offset определяет, какие сообщения считаются обработанными.

**Auto commit**

Offset коммитится автоматически через заданный интервал. Просто в использовании, но даёт at-least-once семантику. При падении consumer между auto commit сообщения обрабатываются повторно.

**Manual commit sync**

Consumer явно коммитит offset синхронно после обработки batch. Блокирует до получения подтверждения. Даёт контроль над моментом commit.

**Manual commit async**

Consumer явно коммитит offset асинхронно. Не блокирует обработку. Быстрее, но нет гарантии успешного commit при падении.

**Commit per message**

Commit после обработки каждого сообщения. Минимизирует повторную обработку, но снижает throughput из-за частых commit.

Выбор стратегии зависит от требований к guarantees и throughput.

### Consumer Lag

Consumer lag — это разница между последним offset в партиции и offset, который обработал consumer. Показывает, насколько consumer отстаёт от producer.

Маленький lag (секунды, минуты) — нормально. Consumer обрабатывает данные почти в реальном времени.

Большой lag (часы, дни) — проблема. Consumer не справляется с нагрузкой. Данные накапливаются необработанными.

Причины большого lag:

- consumer медленно обрабатывает сообщения;
- producer пишет быстрее, чем consumer читает;
- consumer часто падает и перезапускается;
- недостаточно consumers в группе для обработки всех партиций.

Мониторинг consumer lag критичен. Рост lag сигнализирует о проблемах до того, как они станут критическими.

---

## 13. Change Data Capture (CDC): концепция и инструменты

Change Data Capture — это техника отслеживания изменений данных в базе данных и передачи этих изменений в другие системы в реальном времени или близко к нему.

### Зачем нужен CDC

В традиционном batch-подходе данные из БД выгружаются целиком или большими кусками периодически. Это создаёт несколько проблем:

Высокая нагрузка на source БД. SELECT всей таблицы создаёт большую нагрузку, особенно для больших таблиц.

Большая задержка. Данные в аналитической системе отстают на период между выгрузками: час, сутки.

Неэффективность. Если за период изменилось 1% строк, batch-подход всё равно читает и передаёт 100%.

Сложность отслеживания удалений. Batch-подход плохо видит удалённые строки.

CDC решает эти проблемы, передавая только изменения:

- низкая нагрузка на source: читаются только изменения;
- малая задержка: изменения передаются почти мгновенно;
- эффективность: передаётся только то, что изменилось;
- видны все типы изменений: INSERT, UPDATE, DELETE.

### Как работает CDC

CDC работает на уровне БД, отслеживая изменения данных через механизмы самой БД.

Есть несколько способов реализации CDC:

**Trigger-based CDC**

В БД создаются triggers на таблицы. При INSERT/UPDATE/DELETE trigger записывает информацию об изменении в отдельную таблицу. CDC-инструмент читает эту таблицу.

Преимущества:

- работает на любой БД с поддержкой triggers;
- не требует специальных прав.

Недостатки:

- создаёт overhead на каждую операцию записи;
- усложняет схему БД;
- может замедлить production запросы.

**Log-based CDC**

CDC читает транзакционный лог БД. Транзакционный лог (WAL в PostgreSQL, binlog в MySQL, redo log в Oracle) содержит все изменения данных для репликации и восстановления.

CDC-инструмент парсит лог, извлекает изменения, преобразует в события, отправляет в поток.

Преимущества:

- минимальная нагрузка на source БД;
- нет изменений в схеме БД;
- видны все изменения в порядке их возникновения.

Недостатки:

- требует прав на чтение логов БД;
- сложнее настроить;
- зависит от формата логов конкретной БД.

**Query-based CDC**

Периодический SELECT с фильтром по timestamp изменения. Это не настоящий CDC, а incremental batch.

Преимущества:

- простота реализации;
- работает на любой БД.

Недостатки:

- не видны удаления;
- требуется поле updated_at во всех таблицах;
- задержка зависит от периода опроса.

Log-based CDC — предпочтительный подход для production систем.

### События CDC

CDC генерирует события для каждого изменения в БД. Событие содержит:

- тип операции: INSERT, UPDATE, DELETE;
- таблица и схема;
- primary key изменённой строки;
- значения колонок до изменения (для UPDATE и DELETE);
- значения колонок после изменения (для INSERT и UPDATE);
- timestamp изменения;
- метаданные транзакции.

События отправляются в поток (обычно Kafka). Каждая таблица source БД соответствует отдельному topic в Kafka.

Consumer читает события из Kafka и применяет изменения в target системе: аналитической БД, Data Lake, кэше, поисковом индексе.

### Формат событий CDC

Нет единого стандарта формата CDC событий. Разные инструменты используют разные форматы.

Популярный формат — envelope от Debezium. Событие содержит:

- `before` — состояние строки до изменения;
- `after` — состояние строки после изменения;
- `op` — тип операции (c=create, u=update, d=delete, r=read/snapshot);
- `ts_ms` — timestamp события;
- `source` — метаданные источника (БД, таблица, лог позиция).

Для INSERT: `before` пустой, `after` содержит новую строку.

Для UPDATE: `before` содержит старые значения, `after` — новые.

Для DELETE: `before` содержит удалённую строку, `after` пустой.

Это позволяет consumer корректно обработать любой тип изменения.

### Initial Snapshot

При первом запуске CDC нужно передать текущее состояние всех строк таблицы, не только будущие изменения. Это называется initial snapshot.

CDC делает snapshot таблицы без блокировки production операций. Это сложная операция, требующая координации чтения данных и позиции в логе.

После завершения snapshot CDC переключается на чтение логов. С этого момента передаются только изменения.

Snapshot может занять часы или дни для больших таблиц. CDC-инструменты позволяют делать инкрементальные snapshots, разбивая процесс на части.

### Schema Evolution в CDC

Схемы таблиц меняются: добавляются колонки, меняются типы, переименовываются поля.

CDC должен корректно обрабатывать эти изменения. При изменении схемы source таблицы CDC генерирует schema change event.

Consumer видит schema change event и адаптирует target схему. Это может быть автоматическое добавление колонки или ручное вмешательство в зависимости от типа изменения.

Для управления схемами используется Schema Registry. Это централизованный каталог схем сообщений Kafka. CDC пишет схему каждого сообщения в Registry, consumer читает схему оттуда.

Schema Registry поддерживает эволюцию схем с правилами совместимости: forward, backward, full. Это гарантирует, что старые consumers могут читать новые сообщения и наоборот.

---

## 14. Debezium: CDC для реляционных БД

Debezium — это открытая платформа для CDC, построенная на базе Kafka Connect. Debezium превращает изменения в БД в события Kafka.

### Что такое Debezium

Debezium — это набор Kafka Connect connectors для разных БД. Поддерживаются PostgreSQL, MySQL, MongoDB, SQL Server, Oracle, Db2, Cassandra.

Debezium читает транзакционные логи БД, парсит изменения, генерирует события, публикует в Kafka. Всё это происходит с минимальной задержкой и минимальной нагрузкой на source БД.

Debezium использует log-based CDC, что делает его эффективным и надёжным. Нет overhead на production операции. Нет изменений схемы БД.

### Архитектура Debezium

Debezium работает как Kafka Connect connector. Kafka Connect — это фреймворк для интеграции Kafka с внешними системами.

Kafka Connect запускает connector в отдельном процессе. Connector подключается к source БД, читает логи, преобразует в события, пишет в Kafka.

Kafka Connect обеспечивает:

- управление жизненным циклом connectors;
- масштабирование connectors на несколько worker;
- мониторинг и управление через REST API;
- отказоустойчивость через распределённые конфигурации.

Debezium connector конфигурируется через JSON файл или REST API. Конфигурация содержит:

- параметры подключения к БД;
- список таблиц для CDC;
- имена topics в Kafka;
- параметры snapshot и log чтения.

### Debezium для PostgreSQL

Debezium PostgreSQL connector использует logical decoding для чтения WAL (Write-Ahead Log).

Logical decoding преобразует низкоуровневые изменения WAL в понятные события изменения строк. PostgreSQL поддерживает несколько output plugins для logical decoding: pgoutput (встроенный), wal2json, decoderbufs.

Debezium рекомендует использовать pgoutput, так как он встроен в PostgreSQL и не требует установки расширений.

Для включения logical decoding в PostgreSQL нужно:

- установить `wal_level = logical` в postgresql.conf;
- создать replication slot для Debezium;
- дать пользователю права на replication.

Replication slot гарантирует, что PostgreSQL не удалит WAL, пока Debezium не прочитал изменения. Это предотвращает потерю данных при временной недоступности Debezium.

Debezium читает изменения через replication protocol PostgreSQL. Это стандартный протокол репликации, используемый standby серверами.

### Debezium для MySQL

Debezium MySQL connector использует binlog для чтения изменений.

MySQL binlog содержит все изменения данных в формате событий. Debezium парсит binlog, преобразует события в Kafka сообщения.

Для работы Debezium с MySQL нужно:

- включить binlog: `log_bin = ON`, `binlog_format = ROW`;
- установить `binlog_row_image = FULL` для получения полных строк;
- создать пользователя с правами REPLICATION SLAVE, REPLICATION CLIENT.

ROW binlog format критичен. Он записывает изменения как полные строки, а не SQL statements. Это позволяет Debezium видеть точные значения до и после изменения.

Debezium отслеживает binlog позицию (файл и offset). При перезапуске connector продолжает чтение с сохранённой позиции. Позиция хранится в Kafka в отдельном topic.

### Snapshot режим

При первом запуске Debezium делает snapshot всех таблиц.

Процесс snapshot:

1. Debezium блокирует таблицы на чтение (shared lock) для получения консистентного snapshot
2. Читает текущее состояние всех строк
3. Записывает позицию в логе на момент начала snapshot
4. Публикует все строки как INSERT события в Kafka
5. Снимает блокировки
6. Переключается на чтение логов с сохранённой позиции

Блокировка таблиц может быть проблемой для production БД. Debezium поддерживает разные snapshot режимы:

- `initial` — стандартный snapshot с блокировками;
- `never` — пропустить snapshot, начать с текущей позиции лога;
- `when_needed` — делать snapshot только если нет сохранённой позиции;
- `schema_only` — snapshot только схем таблиц, без данных.

Для больших БД используют параллельный snapshot или делают snapshot через отдельный read-replica.

### Tombstone события

Когда строка удаляется из БД, Debezium публикует два события:

DELETE событие с `before` значением и `after=null`.

Tombstone событие — сообщение с тем же ключом, но null payload.

Tombstone нужен для log compaction в Kafka. Compacted topic хранит только последнее значение для каждого ключа. Tombstone удаляет ключ из compacted topic, освобождая место.

Без tombstone удалённые строки навсегда остались бы в compacted topic как последнее известное значение.

### Трансформации в Debezium

Debezium поддерживает Single Message Transforms (SMT) — преобразования событий перед публикацией в Kafka.

Стандартные трансформации:

- фильтрация событий по условию;
- добавление/удаление полей;
- переименование полей;
- роутинг в разные topics по условию;
- маскирование чувствительных данных.

SMT настраиваются в конфигурации connector. Они выполняются в процессе connector до записи в Kafka.

Сложную трансформацию лучше делать в consumer, а не в SMT. SMT должны быть быстрыми и не создавать bottleneck.

### Мониторинг Debezium

Debezium экспортирует метрики через JMX. Ключевые метрики:

- количество обработанных событий;
- lag между текущей позицией лога и позицией Debezium;
- время snapshot;
- количество ошибок;
- размер replication slot.

Рост lag сигнализирует о проблемах: Debezium не справляется с нагрузкой или зависла БД.

Рост replication slot означает накопление непрочитанных логов. Это может привести к переполнению диска на БД сервере.

Мониторинг критичен для production использования Debezium.

---

## 15. Kafka Connect: интеграция источников и приёмников

Kafka Connect — это фреймворк для интеграции Kafka с внешними системами. Connect упрощает перемещение данных между Kafka и БД, файловыми системами, облачными хранилищами, поисковыми индексами.

### Зачем нужен Kafka Connect

Без Connect интеграция требует написания кастомных producers и consumers для каждой системы. Это дублирование кода, сложность поддержки, риск ошибок.

Kafka Connect предоставляет:

- стандартизированный способ интеграции;
- переиспользуемые connectors для популярных систем;
- управление конфигурацией через REST API;
- автоматическое масштабирование и failover;
- мониторинг и управление из единого места.

Connect превращает интеграцию из разработки в конфигурацию. Вместо написания кода настраивается готовый connector.

### Source и Sink Connectors

Есть два типа connectors:

**Source connectors** читают данные из внешней системы и пишут в Kafka. Примеры: JDBC source connector читает данные из БД, S3 source connector читает файлы из S3.

**Sink connectors** читают данные из Kafka и пишут во внешнюю систему. Примеры: JDBC sink connector пишет в БД, Elasticsearch sink connector пишет в Elasticsearch.

Connector запускается внутри Kafka Connect worker. Worker — это процесс, который управляет жизненным циклом connectors, распределяет нагрузку, обеспечивает failover.

### Архитектура Kafka Connect

Kafka Connect может работать в двух режимах:

**Standalone mode**

Один worker процесс на одной машине. Вся конфигурация в файлах. Подходит для разработки и тестирования, не для production.

**Distributed mode**

Кластер из нескольких workers на разных машинах. Конфигурация хранится в Kafka topics. Workers координируются автоматически. Connectors распределяются между workers. При падении worker connector перезапускается на другом worker.

Distributed mode обеспечивает высокую доступность и масштабируемость. Production инсталляции всегда используют distributed mode.

### Connector Configuration

Connector настраивается через JSON конфигурацию. Конфигурация содержит:

- имя connector;
- класс connector (fully qualified Java class name);
- количество tasks (параллелизм);
- параметры подключения к source/sink системе;
- параметры Kafka topics;
- трансформации;
- error handling policy.

Конфигурация отправляется на Kafka Connect кластер через REST API. Workers получают конфигурацию, запускают connector, начинают обработку данных.

### Tasks — параллелизм в Connect

Connector разделяется на tasks. Task — это единица работы, которая реально читает/пишет данные.

Один connector может иметь несколько tasks для параллельной обработки. Tasks распределяются между workers. Это позволяет масштабировать throughput connector.

Количество tasks настраивается параметром `tasks.max`. Не все connectors поддерживают много tasks — зависит от природы источника.

JDBC source connector может создать task на каждую таблицу. S3 source connector может создать task на каждый префикс. File sink connector обычно имеет один task, так как пишет в один файл.

### Offset Management

Source connector должен отслеживать, какие данные уже прочитаны, чтобы не читать дважды. Это называется offset.

Offset хранится в специальном Kafka topic. При перезапуске connector читает offset из этого topic и продолжает с места остановки.

Формат offset зависит от connector. JDBC source connector хранит maximum value прочитанной incremental колонки. Debezium хранит binlog/WAL позицию.

Sink connector не нуждается в offset management. Kafka сама отслеживает consumer offset.

### Типовые Connectors

**JDBC Source Connector**

Читает данные из реляционных БД через JDBC. Поддерживает bulk load и incremental load по timestamp или incrementing колонке.

**JDBC Sink Connector**

Пишет данные из Kafka в реляционные БД через JDBC. Поддерживает insert, upsert, update modes.

**S3 Source Connector**

Читает файлы из S3. Поддерживает разные форматы: JSON, Avro, Parquet.

**S3 Sink Connector**

Пишет данные из Kafka в S3 как файлы. Группирует сообщения в файлы, управляет партиционированием.

**Elasticsearch Sink Connector**

Пишет данные из Kafka в Elasticsearch. Каждое сообщение становится документом в индексе.

**ClickHouse Sink Connector**

Пишет данные из Kafka в ClickHouse. Использует batch inserts для производительности.

### Transforms в Connect

Single Message Transforms (SMT) позволяют изменять сообщения в процессе обработки без написания кода.

Стандартные SMT:

- InsertField — добавить поле;
- ReplaceField — переименовать или удалить поле;
- MaskField — замаскировать значение поля;
- Filter — отфильтровать сообщения по условию;
- TimestampConverter — преобразовать формат времени;
- ExtractField — извлечь вложенное поле на верхний уровень.

SMT настраиваются в connector configuration. Они применяются последовательно как pipeline.

Сложную логику лучше реализовать в отдельном Kafka Streams приложении, а не в SMT.

### Dead Letter Queue

При ошибке обработки сообщения connector может:

- остановиться (fail);
- пропустить сообщение (ignore);
- записать сообщение в Dead Letter Queue topic (DLQ).

DLQ topic содержит сообщения, которые не удалось обработать, вместе с информацией об ошибке. Это позволяет не терять данные и разбирать проблемы отдельно.

DLQ настраивается в connector configuration:

- `errors.tolerance` = all (продолжать при ошибках);
- `errors.deadletterqueue.topic.name` = имя DLQ topic;
- `errors.deadletterqueue.context.headers.enable` = true (записывать контекст ошибки).

После исправления проблемы сообщения из DLQ можно переобработать.
