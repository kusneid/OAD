# Оперативный анализ данных
## Информация о курсе
![alt text](<attachments/Pasted image 20251210003842.png>)

## Описание курса
Курс предназначен прежде всего для таких специальностей как дата-аналитик, дата-инженер, ml-инженер, bi-аналитик, системный аналитик(сбор требований для витрины в лабах мб??) и нацелен на получение студентами практических навыков 
- проектирования и разработки ETL процессов
- анализ сформированной студентом витрины через BI инструменты
- реализация фичей для ML моделей, построенных на основе данных из созданной студентом витрины
(прим. - что лабы что лекции выстроены именно так, мы сначала строим витрину, потом анализируем и делаем мл модельки)
![alt text](<attachments/Pasted image 20251210010223.png>)
## Используемые технологии
В рамках курса студент изучит такие технологии как:
DE/DWH dev: Kafka Airflow Spark Clickhouse MinIO PostgreSQL dbt
BI: Apache Superset, Yandex Datalens
ML: pandas scikit-learn Linear Regression K-Means
![alt text](<attachments/Pasted image 20251210010617.png>)
В Big Data мире технологий больше, чем можно представить и у каждой компании свой стек для решения своих задач со своими конкретными бюджетами и запросами, поэтому чтобы не распылять внимание на все были выбраны самые используемые на момент 25 года технологии (прим. которые легко развернуть, тот же apache iceberg и apache hadoop популярны но касаться будем только теоритически тк для нормального деплоя у каждого студента потребуется вечность :) )

## Примеры ETL процессов
первый модуль посвящен построению ETL процесса для преобразования сырых исходных данных в агрегированную витрину
![alt text](<attachments/Pasted image 20251210011602.png>)
## Исходные данные
В нашем случае исходными данными являются датасеты из открытых источников - 
Kaggle, HuggingFace, отдельные сайты с архивами (прим. можно как по вариантам сделать так и одинаковым всё)
Базы данных зачастую используются, когда надо уже очищенные данные сформировать в виде витрины
REST API запросы используются для передачи данных из веб-приложений, мобильных приложений и тд в хранилище сырых данных (RAW слой)

Пример- Вася Пупкин отправил Вове Пукину 10000руб - данные об этой транзакции и об обновленных данных счетов пользователей уходят не только в БД при самом мобильном приложении (оно используется для других целей, для быстрого доступа к данным в частности), но и в RAW слой хранилища данных для последующей очистки, агрегации и построения витрины по этим данным

## RAW слой дата-платформы 
![alt text](<attachments/Pasted image 20251210013842.png>)
RAW слой представляет из себя набор неструктурированных неочищенных данных, зачастую для хранения таких данных используются такие инструменты как Apache Hadoop, S3 или отдельные схемы в БД созданные специально для таких данных

Примеры:
S3 - это облачное объектное хранилище для файлов любого типа и объема, данные хранятся в бакетах, можно хранить как и обычные файлы(как картинки для вашего проекта по РИПу), так и табличные данные
Apache Hadoop — это фреймворк/платформа с открытым исходным кодом для распределённого хранения и обработки больших наборов данных (Big Data) с использованием кластеров компьютеров. Он разбивает данные и задачи на части, которые параллельно обрабатываются на множестве узлов, что позволяет быстро анализировать огромные объёмы информации. Архитектура хадупа гораздо сложнее S3

## Staging слой

Staging слой представляет собой уже очищенные, нормализованные данные, пригодные для построения витрин для дальнейшей аналитики/обучения мл моделей

## Aggregated слой
Слой для витрин, пригоден для дальнейшей аналитики...
