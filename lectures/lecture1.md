# Оперативный анализ данных
## Информация о курсе
![[attachments/Pasted image 20251210003842.png]]

## Описание курса
Курс предназначен прежде всего для таких специальностей как дата-аналитик, дата-инженер, ml-инженер, bi-аналитик, системный аналитик(сбор требований для витрины в лабах мб??) и нацелен на получение студентами практических навыков 
- проектирования и разработки ETL процессов
- анализ сформированной студентом витрины через BI инструменты
- реализация фичей для ML моделей, построенных на основе данных из созданной студентом витрины
(прим. - что лабы что лекции выстроены именно так, мы сначала строим витрину, потом анализируем и делаем мл модельки)
![[attachments/Pasted image 20251210010223.png]]
## Используемые технологии
В рамках курса студент изучит такие технологии как:
DE/DWH dev: Kafka Airflow Spark Clickhouse MinIO PostgreSQL dbt
BI: Apache Superset, Yandex Datalens
ML: **ахтунг добавить**

![[attachments/Pasted image 20251210010617.png]]
В Big Data мире технологий больше, чем можно представить и у каждой компании свой стек для решения своих задач со своими конкретными бюджетами и запросами, поэтому чтобы не распылять внимание на все были выбраны самые используемые на момент 25 года технологии (прим. которые легко развернуть, тот же apache iceberg и apache hadoop популярны но касаться будем только теоритически тк для нормального деплоя у каждого студента потребуется вечность :) )

## Примеры ETL процессов
первый модуль (образно, пока не разделил нормально!!!!!!!) посвящен построению ETL процесса для преобразования сырых исходных данных в агрегированную витрину
![[attachments/Pasted image 20251210011602.png]]
## Исходные данные
В нашем случае исходными данными являются датасеты из открытых источников - 
Kaggle, HuggingFace, отдельные сайты с архивами (прим. можно как по вариантам сделать так и одинаковым всё)
Базы данных зачастую используются, когда надо уже очищенные данные сформировать в виде витрины
REST API запросы используются для передачи данных из веб-приложений, мобильных приложений и тд в хранилище сырых данных (RAW слой)

Пример- Вася Пупкин отправил Вове Пукину 10000руб - данные об этой транзакции и об обновленных данных счетов пользователей уходят не только в БД при самом мобильном приложении (оно используется для других целей, для быстрого доступа к данным в частности), но и в RAW слой хранилища данных для последующей очистки, агрегации и построения витрины по этим данным

## RAW слой дата-платформы 
![[attachments/Pasted image 20251210013842.png]]
RAW слой представляет из себя набор неструктурированных неочищенных данных, зачастую для хранения таких данных используются такие инструменты как Apache Hadoop, S3 или отдельные схемы в БД созданные специально для таких данных 