## Слайд 1. Зачем моделирование данных в аналитике

### Суть концепции

**Моделирование данных** — способ зафиксировать смысл таблиц так, чтобы данные оставались интерпретируемыми при росте объёма, числа источников и количества трансформаций. Модель отвечает на вопросы: что означает строка, какие поля задают уникальность, какие связи допустимы, где и как хранится история изменений. Это не про “нарисовать ER-диаграмму”, а про создание стабильной семантической рамки, внутри которой вычисления метрик становятся воспроизводимыми.

### Как работает

Модель задаёт **контракты** на наборы данных: зерно (grain), ключи, кардинальности связей, правила историзации. Как только эти вещи зафиксированы, появляется возможность строить не только SQL-запросы, но и проверки, которые защищают от тихих дефектов: дубли ключей, many-to-many join, незаметная смена гранулярности, “перекраска” истории актуальными атрибутами.

Модель живёт не в одном слое. Интеграционный слой обычно допускает большую гибкость и хранит больше “фактов как пришли”, а слой потребления требует строгости: одни и те же сущности и определения должны работать годами. Отсюда типовой дизайн: сначала структура, удобная для интеграции и историзации, затем структура, удобная для аналитических запросов и BI/ML.

### Проблемы и ограничения

Без модели система чаще всего ломается не ошибками выполнения, а ошибками смысла. Пайплайн может завершаться успешно, таблицы обновляться, но метрики будут зависеть от деталей загрузки и случайных изменений в источниках. Ещё один класс проблем — эксплуатационный: отсутствие модели делает невозможным быстрый поиск причин расхождений, потому что непонятно, какие инварианты должны выполняться и где их проверять.

### Практические аспекты

Модель должна быть проверяемой: уникальность ключей, ссылочная целостность на уровне аналитических тестов, контроль кардинальности, контроль “as-of join” для истории. В промышленной аналитике это превращает модель в актив: она не только описывает данные, но и задаёт автоматические барьеры допуска в слой потребления.

### Схема

```text
Смысл и стабильность (модель) — поперёк слоёв

RAW        STAGING        INTEGRATION            CONSUMPTION
 |            |               |                        |
 |  факт поставки   типы/ключи/дедуп     семантика, grain, история
 |------------|---------------|------------------------|
               Модель задаёт: ключи, связи, правила изменений
```

---

## Слайд 2. Зерно (**grain**) как главный регулятор корректности

### Суть концепции

**Grain** — точное определение того, что представляет одна строка таблицы. Grain определяет, какой ключ обязан быть уникальным и какие агрегации допустимы без двойного счёта. Если grain не сформулирован явно, таблица превращается в “мешок данных”, где любые join и суммы могут давать случайный результат.

### Как работает

Grain фиксируется как:

1. словесное определение строки;
    
2. набор колонок, образующих **ключ зерна** (uniqueness key);
    
3. допустимые связи с другими таблицами (ожидаемая кардинальность).
    

Один и тот же предмет анализа может существовать в разных зернах, и это нормально: event-level для детального анализа, transaction-level для финансовых мер, snapshot-level для быстрых BI-метрик. Ошибки начинаются, когда эти зерна смешиваются без явного преобразования: например, event-level факты соединяются со справочником, который перестал быть уникальным, и превращаются в many-to-many.

### Проблемы и ограничения

Главный провал — “скрытая смена зерна”. Она часто случается при join: таблица выглядела как `user×day`, но после присоединения справочника с дублями стала `user×day×version`, и всё продолжило работать, только метрики удвоились. Второй провал — неправильный ключ зерна: если ключ не детерминирован или не контролируется, дедупликация и инкрементальная обработка становятся нестабильными.

### Практические аспекты

Grain проектируют сверху вниз: сначала решают, какие таблицы должны быть базовыми фактами (в каком зерне), затем какие измерения к ним присоединяются, затем какие производные таблицы агрегируются. Для каждой таблицы фиксируют:

- ключ зерна (уникальность),
    
- ожидаемые кардинальности связей (1:1, 1:N, N:1),
    
- допустимые меры (что суммируемо, что нет).
    

### Схемы зерна

```text
Три типовых зерна и их ключи

EVENT-LEVEL (строка = событие)
  key: (event_id)  или (source_id, event_id)

TRANSACTION-LEVEL (строка = операция/транзакция)
  key: (transaction_id)

SNAPSHOT-LEVEL (строка = срез состояния)
  key: (entity_id, date)  например (user_id, date)
```

```text
Как grain ломается при неправильном join (кардинальность)

dim_X должно быть 1 row на key
  dim_X(key)  ----1---->  fact(..., key)

если dim_X стало N rows на key:
  dim_X(key, version)  ----N---->  fact(..., key)

результат:
  fact после join размножается => двойной счёт метрик
```

---

## Слайд 3. **Star Schema**: структура потребления “факт в центре, измерения вокруг”

### Суть концепции

**Star Schema** — модель потребления, где центральная таблица фактов содержит меры и ссылки на измерения, а измерения содержат атрибуты для фильтров и группировок. Эта модель строится вокруг аналитического запроса как базовой операции: “агрегировать меры факта по атрибутам измерений”. Star не оптимизирует интеграцию источников; она оптимизирует стабильные запросы и предсказуемость смысла.

### Как работает

В звезде факт фиксирует grain и хранит **surrogate keys** измерений (технические ключи). Измерения содержат атрибуты, которые редко меняются на уровне строк факта, но часто используются в аналитике. В результате:

- факт большой и “узкий” по контексту (ключи + меры),
    
- измерения относительно небольшие, но “широкие” по атрибутам.
    

Важная часть механики звезды — разделение “меры vs контекст”. Меры живут в факте. Контекст живёт в измерениях. Если контекст записывают в факт без дисциплины, появляются дублирование, разъезд значений и невозможность поддерживать историю.

### Проблемы и ограничения

Star Schema требует дисциплины в ключах и измерениях. Если измерение не уникально по своему натуральному ключу, join разрушает корректность метрик. Если измерения меняются во времени, нужно заранее выбрать стратегию историзации (SCD), иначе прошлые факты начнут присоединяться к “сегодняшним” атрибутам.

### Практические аспекты

Star Schema чаще всего является основой BI-слоя и аналитических витрин, потому что:

- запросы читаются прямолинейно,
    
- семантика стабильна,
    
- контроль качества проще (контроль ключей и кардинальностей).  
    При этом звезда не отменяет существование широких денормализованных таблиц в потреблении: они часто являются проекциями звезды под конкретные типовые запросы.
    

### Схема звезды (псевдо-диаграмма)

```text
               dim_date
                 |
                 | date_key
dim_user --- user_key   fact_events   event_type_key --- dim_event_type
                 |
               dim_geo
```

### Псевдо-схемы таблиц (как структура, не “пример данных”)

```text
fact_events
- event_sk            (optional technical PK)
- event_id            (natural id, optional / degenerate)
- date_key            (FK -> dim_date)
- user_key            (FK -> dim_user)
- geo_key             (FK -> dim_geo)
- event_type_key      (FK -> dim_event_type)
- measures...         (numeric columns, flags)

dim_user
- user_key            (surrogate PK)
- user_id             (natural key)
- attributes...       (country, platform, segment, ...)

dim_date
- date_key            (surrogate PK)
- date, week, month, quarter, year, ...

dim_event_type
- event_type_key      (surrogate PK)
- event_type_code, event_type_name, ...
```

---

## Слайд 4. Измерения в звезде: ключи, конформность, управление атрибутами

### Суть концепции

**Dimension** — таблица контекста, которая описывает сущность через атрибуты и обеспечивает стабильные срезы анализа. Измерение обязано иметь устойчивый ключ и управляемую семантику атрибутов, иначе звезда деградирует: факты соединяются неверно, исторические отчёты “перекрашиваются”, а фильтры начинают вести себя непредсказуемо.

### Как работает

Ключевой механизм — разделение **natural key** и **surrogate key**:

- natural key нужен для сопоставления с источниками;
    
- surrogate key нужен для стабильных ссылок из фактов и для историзации.
    

**Conformed dimensions** означают, что одно измерение используется несколькими фактами одинаково: один справочник “пользователь” и один справочник “дата” обслуживают разные наборы фактов. Это устраняет ситуацию “две страны у одного и того же пользователя в разных отчётах”, потому что атрибуты формируются в одном месте и распространяются через ключ.

Измерения могут быть:

- “обычными” (user, product, geo),
    
- “role-playing” (одна и та же таблица даты играет роли: created_date, paid_date, shipped_date — разные FK на одну dim_date),
    
- “degenerate” (натуральный идентификатор факта хранится в факте как атрибут без отдельного измерения, если он нужен для drill-down, но не имеет собственных атрибутов).
    

### Проблемы и ограничения

Главная проблема измерений — нарушение уникальности на natural key (или на бизнес-ключе). Вторая проблема — изменения атрибутов во времени: без SCD прошлые факты будут присоединяться к актуальным атрибутам, и отчёты “за прошлый год” изменятся после обновления справочника. Третья проблема — “мягкие” домены: если статусы/категории в измерении не контролируются, BI получает неожиданное появление новых значений и разъезд сегментаций.

### Практические аспекты

Для измерений обычно фиксируют:

- business key (natural),
    
- surrogate key,
    
- правила уникальности,
    
- правила допустимых значений по ключевым атрибутам,
    
- стратегию историзации (нет / перезапись / версии).  
    Именно измерения чаще всего становятся местом, где формализуют смысл категорий и атрибутов, чтобы downstream-слои не “додумывали” интерпретации.
    

### Схема ключей измерения и конформности

```text
                +------------------+
sources ----->  |  dim_user        |
                |  user_key (SK)   |
                |  user_id  (NK)   |
                +------------------+
                      ^      ^
                      |      |
                      |      +-- business matching (NK)
                      |
        +--------------------------+     +--------------------------+
        | fact_events              |     | fact_payments            |
        | user_key  (FK -> dim)    |     | user_key  (FK -> dim)    |
        +--------------------------+     +--------------------------+

Одна dim_user обслуживает несколько фактов => conformed dimension
```

---

## Слайд 5. Факты в звезде: меры, аддитивность, семантические ограничения

### Суть концепции

**Fact table** фиксирует измеримые события/операции на определённом grain и содержит меры, которые используются для агрегирования. Факт — это не “таблица с числами”, а строго определённая конструкция: grain + внешние ключи на измерения + меры с правилами агрегирования. Ошибка в факте почти всегда дороже ошибки в измерении, потому что факт обычно самый большой по объёму и именно он участвует в большинстве вычислений.

### Как работает

Факт формируется так, чтобы каждая строка была атомарной для выбранного grain. Затем аналитические запросы строятся как агрегирование мер факта с группировками по атрибутам измерений. Для корректности важно классифицировать меры по аддитивности:

- **additive**: можно суммировать по всем измерениям и по времени;
    
- **semi-additive**: можно суммировать по измерениям, но не по времени (типично “состояние на момент”);
    
- **non-additive**: нельзя суммировать, требуется вычисление из компонентов (доли, проценты, средние).
    

Эта классификация влияет на то, что хранить в факте. Часто в факте хранят компоненты для корректного пересчёта (например, числитель и знаменатель), а не готовый процент, чтобы исключить ошибки агрегирования.

### Проблемы и ограничения

Факты ломаются в трёх местах:

1. нарушение grain (две строки там, где должна быть одна) — метрики удваиваются/утраиваются;
    
2. дубли из источника или из инкрементальной загрузки — факты перестают быть атомарными;
    
3. неверные кардинальности связей — join к измерениям раздувает факт и делает агрегаты некорректными.
    

Ещё одна проблема — “смешение типов фактов”. Таблица, которая одновременно пытается быть event-level и snapshot-level, становится невалидной для большинства запросов: часть мер относится к событиям, часть — к состоянию, и ни одна не агрегируется предсказуемо.

### Практические аспекты

Для факта фиксируют:

- grain и ключ зерна,
    
- обязательные FK на измерения,
    
- набор мер и правила их агрегирования,
    
- политику дедупликации и инкрементальной публикации (перезапись партиций/идемпотентность).  
    Это делает факт управляемым: можно автоматизировать проверки уникальности ключа зерна и коэффициента раздувания после join, а также реконсиляции сумм между слоями.
    

### Схема “факт как центр семантики мер”

```text
fact_* = grain + FKs + measures

            dim_date (date_key)
                   |
dim_user (user_key) |      dim_geo (geo_key)
        \           |           /
         \          |          /
          +-------------------+
          |      fact_*       |
          |  FKs: user, date  |
          |       geo, ...    |
          |  measures: ...    |
          +-------------------+

Правила:
- grain задаёт уникальность строки
- FKs задают допустимые разрезы
- меры имеют правила агрегирования
```

---

## Слайд 6. Типы fact-таблиц: **transaction fact** как “атомарный журнал”

### Суть концепции

**Transaction fact** — факт-таблица, где каждая строка соответствует одной операции/событию бизнес-уровня (транзакция, заказ, платеж, действие) и представляет собой “журнал” атомарных записей. Это базовый тип факта, от которого строятся почти все производные агрегаты, потому что он сохраняет максимальную детализацию и допускает повторные пересчёты с другой логикой.

### Как работает

Transaction fact строится вокруг жёсткого grain: “одна строка = одна транзакция”. Это означает:

- существует натуральный идентификатор операции (или комбинация полей), который должен быть уникален;
    
- меры в строке относятся только к этой операции (а не к состоянию на дату);
    
- факт содержит ссылки на измерения, которые описывают контекст операции (кто, когда, где, какой тип).
    

Архитектурно transaction fact обычно является самым “длинным” фактом (много строк) и одним из основных источников нагрузок на join и агрегации. Именно поэтому transaction fact проектируют так, чтобы:

- ключ зерна был детерминирован и проверяем;
    
- дубли не проходили в потребление;
    
- типы мер были корректно классифицированы (что суммируется, что нет).
    

### Проблемы и ограничения

Transaction fact уязвим к повторам и ретраям источника: если одно событие может приехать дважды, уникальность ключа зерна нарушается и все downstream-агрегаты начинают “пухнуть”. Вторая проблема — изменяемость фактов: часть транзакционных источников присылает “обновления” операции (статус, сумма, исправления). Тогда transaction fact требует либо модели “append-only + последняя версия”, либо выделения “саттелита” истории, либо перезаписи партиции/операции по правилам.

### Практические аспекты

Transaction fact удобно использовать как точку аудита: можно объяснить, из каких атомарных операций складывается агрегат. Поэтому в transaction fact часто оставляют “degenerate” атрибуты (например, внешний идентификатор операции, номер документа), которые не являются измерениями, но нужны для трассировки и проверки.

### Схема transaction fact

```text
                 dim_date
                   |
                 date_key
                   |
dim_user --user_key--+           +-- event_type_key -- dim_event_type
                     |           |
                     |        fact_transaction
dim_geo  --geo_key---+           |
                     |           +-- measures (atomic per transaction)
                     |
               (grain: 1 row = 1 transaction)

Ожидаемая кардинальность:
- dim_* -> fact_transaction : N:1 (много фактов на одну строку измерения)
- ключ зерна факта уникален
```

```text
Ключевая идея:
transaction fact = "журнал" событий
snapshot fact     = "состояние/итог" на период
```

---

## Слайд 7. Типы fact-таблиц: **periodic snapshot** как “срез по периоду”

### Суть концепции

**Periodic snapshot fact** — факт, где каждая строка представляет состояние/итоги за фиксированный период по сущности: чаще всего день/неделя/месяц. Это не журнал событий, а регулярный “срез” агрегатов. Его делают, когда основное потребление — BI с типовыми метриками по периодам, а запросы по transaction fact слишком тяжелы или слишком детальны.

### Как работает

Grain snapshot-таблицы обычно вида: `entity × period`. Например: `user × day`, `product × day`, `geo × day`. В строке лежат уже агрегированные показатели за период: суммы, счётчики, флаги активности, длительности. Это обеспечивает:

- быстрые запросы: большинство BI-графиков строится без тяжёлых join на большой факт;
    
- стабильность: “день закрыт” означает, что срез за день фиксирован и пересчитывается по правилам late arrivals.
    

Snapshot fact почти всегда производная от transaction fact или event-level данных. Отличие в том, что snapshot задаёт фиксированную гранулярность и снимает необходимость регулярно пересчитывать “с нуля” на потреблении.

### Проблемы и ограничения

Главный риск snapshot — несовместимость периодов из-за опоздавших данных и пересчётов. Если день публикуется как “готовый”, а затем доприходят события, нужно либо пересчитывать и перезаписывать день, либо вводить слой корректировок. Второй риск — неправильная интерпретация мер: некоторые показатели не аддитивны по времени (балансы, стоки), и snapshot по дням нельзя суммировать “за месяц” без отдельного правила.

Ещё одна проблема — расширение набора метрик. Snapshot факты часто растут в ширину (много колонок), потому что одна таблица обслуживает множество метрик. Это нормально для потребления, но требует дисциплины: единые определения, контроль типов, версионирование метрик при изменениях логики.

### Практические аспекты

Snapshot fact обычно проектируют с явной политикой:

- period_key (date_key) как обязательная часть ключа зерна,
    
- idempotent publish (перезапись партиции периода),
    
- статусы готовности периода (partial/complete), если потребителям важно отличать неполный день.
    

### Схема periodic snapshot

```text
                        dim_date
                          |
                        date_key
                          |
dim_user --user_key--------+          +-- geo_key -- dim_geo
                           |          |
                           |     fact_user_day_snapshot
                           |          |
                           +-- measures (daily aggregates)
                               (grain: 1 row = 1 user x 1 day)

Отличие от transaction fact:
- факт хранит итоги за период
- события внутри периода не представлены строками
```

---

## Слайд 8. Типы fact-таблиц: **accumulating snapshot** как “жизненный цикл в одной строке”

### Суть концепции

**Accumulating snapshot** — факт, который хранит “прогресс” сущности через последовательность стадий. Он отличается от periodic snapshot тем, что строка не “замораживается” каждый период, а обновляется по мере прохождения этапов. Это модель для процессов, где есть понятие жизненного цикла: старт → этап1 → этап2 → завершение, и важно измерять времена между стадиями.

### Как работает

Grain: “одна строка = один процессный объект” (например, один order, один ticket, один workflow instance).  
В строке хранятся ключи измерений и несколько дат/статусов, соответствующих стадиям процесса. Важно, что часть полей заполняется позже, поэтому строка обновляется.

Ключевой эффект: запросы на “сколько объектов на стадии”, “среднее время между этапами”, “доля завершённых” становятся простыми и быстрыми, потому что все ключевые временные отметки лежат в одной строке, а не размазаны по событиям.

### Проблемы и ограничения

Accumulating snapshot плохо сочетается с append-only хранением без обновлений: требуется механизм обновления строки или публикации версий. Вторая проблема — переопределение стадий: если бизнес/источник меняет модель процесса, схема accumulating snapshot может ломаться или требовать расширения. Третья — корректность времени: нужны строгие правила, какие времена считаются истинными (event_time vs load_time), и как обрабатываются поздние события, иначе интервалы становятся неверными.

### Практические аспекты

В аналитических платформах accumulating snapshot часто строят как производный слой: на нижнем уровне остаются события (transaction/event fact), а accumulating — агрегированная “проекция” жизненного цикла для BI. Это уменьшает сложность потребления, но требует дисциплины обновлений и качества источника.

### Схема accumulating snapshot

```text
dim_user --user_key------------------+
                                     |
dim_date (role-playing)              |
  created_date_key  -----------------+ 
  approved_date_key -----------------+     fact_process_accum
  shipped_date_key  -----------------+     (grain: 1 row = 1 entity)
  closed_date_key   -----------------+     columns: stage dates, status, measures
                                     |
dim_status --status_key--------------+

Role-playing dim_date:
одна и та же таблица даты используется в разных "ролях" этапов
```

---

## Слайд 9. Role-playing dimensions и мосты: как модель удерживает сложные связи

### Суть концепции

В звезде одна и та же сущность-измерение может использоваться в разных смысловых ролях. Типичный случай — **dim_date**: дата создания, дата оплаты, дата доставки. Это не “три измерения”, а одно измерение даты, подключаемое к факту несколькими внешними ключами. Это удерживает семантику времени стабильной и избегает дублирования справочника.

Второй класс конструкций — мосты (**bridge**) для связей, которые не укладываются в один FK. Например, если у факта может быть несколько категорий/тегов/атрибутов, связь становится many-to-many, и вместо прямого поля используют bridge-таблицу.

### Как работает

Role-playing dimension:

- в факте несколько FK на одну dim-таблицу;
    
- каждый FK имеет чётко определённый смысл;
    
- BI использует конкретную роль даты в запросах.
    

Bridge:

- отдельная таблица связывает факт (или измерение) с набором значений другой сущности;
    
- bridge контролирует кардинальность и позволяет хранить веса/приоритеты, если нужно.
    

### Проблемы и ограничения

Role-playing ломается, когда роли нефиксированы и начинают интерпретироваться по-разному (например, “дата операции” в одном отчёте = created, в другом = paid). Bridge-таблицы опасны тем, что могут неожиданно создавать раздувание строк в агрегациях, если потребитель делает join без осознания many-to-many. В модели это решается явной маркировкой: где 1:N, где N:M, и какие запросы требуют distinct/весов.

### Схемы

Role-playing:

```text
                 dim_date
                   ^
                   | (created_date_key)
                   |
fact_orders --------+
                   |
                   | (paid_date_key)
                   v
                 dim_date

Одна dim_date, два FK с разным смыслом
```

Bridge (many-to-many):

```text
fact_entity (entity_key, measures...)
   |
   | 1:N
   v
bridge_entity_tag (entity_key, tag_key)
   ^
   | N:1
   |
dim_tag (tag_key, tag_name, ...)
```

---

## Слайд 10. Подготовка к SCD: почему “измерения меняются” и что ломается без историзации

### Суть концепции

Измерения описывают атрибуты сущностей (пользователь, продукт, канал, география), и эти атрибуты меняются во времени. Если измерение хранится только в актуальном виде, прошлые факты будут интерпретироваться через текущие атрибуты. Это ломает ретроспективные отчёты: показатели “по стране” за прошлый год изменятся после того, как страна у сущности обновилась сегодня.

SCD (slowly changing dimensions) — семейство подходов, которые определяют, как хранить изменения атрибутов измерений и как соединять факты с правильной версией атрибутов.

### Как работает

Проблема сводится к вопросу: когда факт произошёл, какой набор атрибутов считался истинным?  
Для ответа нужны два элемента:

1. в измерении должна существовать история версий атрибутов;
    
2. join факта к измерению должен быть **as-of**: привязка к версии, актуальной на момент факта.
    

Если этого нет, получается “перекраска истории”: факты остаются прежними, но их группировки меняются из-за изменения атрибутов измерения.

### Проблемы и ограничения

Историзация увеличивает объём и усложняет join. Если делать её без дисциплины, появляются перекрывающиеся интервалы версий, дубли активных записей, невозможность однозначно выбрать версию. Ещё одна сложность — источник может присылать изменения задним числом, и тогда требуется backfill или пересчёт связей фактов с измерением.

### Практические аспекты

Перед выбором SCD-стратегии фиксируют:

- какие атрибуты должны иметь историю (не все);
    
- для каких отчётов нужна “истина на момент события”, а для каких — “актуальная классификация”;
    
- как будут обрабатываться late updates и переоткрытие прошлых периодов.
    

### Схема проблемы “перекраски истории”

```text
Без SCD:
fact (event_time, user_key) ----> dim_user (country = CURRENT)

Если country изменился сегодня,
то факт годичной давности группируется по новой стране.

Нужно:
fact(event_time) ----as-of----> dim_user_versioned(country, valid_from, valid_to)
```

---
## Слайд 11. Data Vault: зачем он нужен рядом со Star Schema

### Суть концепции

**Data Vault** — модель интеграционного слоя, спроектированная так, чтобы выдерживать частые изменения источников, хранить полную историю и обеспечивать аудит того, “что именно пришло и когда”. В отличие от Star Schema, которая оптимизирует потребление (BI-запросы, стабильные измерения и факты), Data Vault оптимизирует **интеграцию**: много источников, нестабильные схемы, необходимость хранить исходные бизнес-ключи и происхождение данных.

Data Vault строится вокруг раздельного хранения:

- ключей сущностей,
    
- связей между сущностями,
    
- атрибутов сущностей и их исторических изменений.
    

Эта раздельность кажется избыточной по числу таблиц, но она позволяет менять правила представлений (как собираются измерения и факты) без разрушения интеграционного слоя. DV слой становится “хранилищем фактов о фактах”: он фиксирует, что именно загрузили, из какого источника, в какой момент, и что изменилось.

### Как работает

DV отделяет **идентичность** сущности от её **атрибутов**. Идентичность выражается через бизнес-ключ (natural key): например, `user_id` из источника. Он попадает в Hub. Атрибуты (страна, платформа, свойства) попадают в Satellites, которые версионируются по времени загрузки и изменению содержимого. Связи между сущностями (пользователь связан с событием, операция связана с документом) попадают в Links.

DV специально ориентирован на “append-only” историю: вместо перезаписи строк создаются новые записи спутников, когда атрибуты изменились. Из этого легко собрать состояние “на момент” или “по последней версии”, а также легко доказать происхождение каждой версии.

### Проблемы и ограничения

DV увеличивает сложность: становится больше таблиц, запросы для конечного потребления сложнее, а сборка витрин требует отдельного слоя представлений. DV не является слоем, на котором удобно строить BI напрямую: для BI он слишком нормализован и требует много join, которые становятся дорогими на широких аналитических запросах.

DV также требует дисциплины:

- единые правила генерации hash keys,
    
- единые правила “что считается изменением” (hashdiff),
    
- недопущение дублей “одной и той же версии”,
    
- стабильная фиксация record_source и load_ts.
    

### Практические аспекты

Типовой реальный паттерн: DV как интеграционный слой → дальше сборка Star Schema и/или широких витрин как слоя потребления. DV позволяет держать “истину о поставке”, а потребительский слой — “истину о метриках и удобстве запросов”. Это разделяет ответственность: изменения источников и интеграции решаются в DV, изменения витрин — на уровне представлений без ломания интеграционного хранения.

### Схема позиционирования DV

```text
Sources -> RAW/STAGING -> Data Vault (Integration) -> Star/Marts (Consumption)

                +-----------------------------+
                |        Data Vault           |
                |  Hubs (keys)                |
                |  Links (relationships)      |
                |  Satellites (attributes+hist|
                +-----------------------------+
                             |
                             v
                    +----------------+
                    | Star / Marts   |
                    | Facts+Dims     |
                    +----------------+
```

---

## Слайд 12. Data Vault компоненты: **Hubs / Links / Satellites** (структура и смысл)

### Суть концепции

DV разлагает модель на три типа таблиц:

- **Hub**: “кто/что это?” — хранит бизнес-ключ сущности и технический hash key.
    
- **Link**: “как связано?” — хранит связь между hub’ами (и при необходимости ключ самой связи).
    
- **Satellite**: “какие атрибуты и как менялись?” — хранит атрибуты и историю изменений по времени загрузки.
    

Этот треугольник позволяет:

- хранить ключи независимо от атрибутов,
    
- добавлять новые атрибуты (новые satellites) без изменения hub,
    
- добавлять новые связи (новые links) без изменения hub,
    
- хранить историю как последовательность версий.
    

### Как работает

**Hub** содержит:

- `*_hk` (hash key сущности) — surrogate идентификатор в DV,
    
- `*_bk` (business key) — натуральный ключ (из источника),
    
- `load_ts` — время загрузки в DV,
    
- `record_source` — откуда пришло.
    

**Link** содержит:

- `link_hk` — hash key самой связи,
    
- набор `*_hk` участников связи,
    
- `load_ts`, `record_source`.
    

**Satellite** содержит:

- ссылку на hub/link (через hk),
    
- набор атрибутов,
    
- `load_ts`,
    
- `hashdiff` — хэш атрибутов для определения изменений,
    
- (опционально) `effective_from/effective_to`, если отделяют “время загрузки” от “время действия”.
    

### Проблемы и ограничения

Слабое место — неправильное разнесение атрибутов. Если атрибуты начинают попадать в hub/link, DV теряет свою цель: hub должен быть минимальным и стабильным. Второе слабое место — слишком “толстые” satellites без версионирования по hashdiff: тогда история превращается в дубликаты и непонятно, что изменилось. Третье — отсутствие record_source: тогда невозможно разобраться в конфликтующих версиях из разных источников.

### Практические аспекты

Обычно делают несколько satellites на одну сущность: по группам атрибутов с разной частотой изменения и разной ответственностью. Это позволяет не перезаписывать “редко меняющиеся” атрибуты вместе с “часто меняющимися” и уменьшает объём истории.

### Псевдо-схема DV (как “рисунок”)

```text
          HUB_USER                          HUB_EVENT
   +-------------------+              +-------------------+
   | user_hk (PK)      |              | event_hk (PK)     |
   | user_bk           |              | event_bk          |
   | load_ts           |              | load_ts           |
   | record_source     |              | record_source     |
   +---------+---------+              +---------+---------+
             |                                  |
             |                                  |
             |                                  |
             v                                  v
     SAT_USER_ATTR                       SAT_EVENT_ATTR
 +-------------------+              +-------------------+
 | user_hk (FK)      |              | event_hk (FK)     |
 | load_ts           |              | load_ts           |
 | hashdiff          |              | hashdiff          |
 | attrs...          |              | attrs...          |
 +-------------------+              +-------------------+

             \                                  /
              \                                /
               \                              /
                v                            v
                       LINK_USER_EVENT
                 +---------------------------+
                 | link_hk (PK)              |
                 | user_hk (FK -> hub_user)  |
                 | event_hk(FK -> hub_event) |
                 | load_ts                   |
                 | record_source             |
                 +---------------------------+
```

---

## Слайд 13. Историзация в DV: **load_ts**, **hashdiff**, “что считается изменением”

### Суть концепции

DV хранит историю через Satellites: каждая строка satellite — версия атрибутов на момент загрузки. Вопрос “изменилось ли что-то?” решается через **hashdiff** — хэш от набора атрибутов, который позволяет отличать новую версию от дубля.

Ключевой момент: DV в первую очередь фиксирует **историю загрузки** (что мы получили и когда), а не обязательно “историю действия” (когда это было истинно в бизнес-времени). Поэтому в саттелитах почти всегда есть `load_ts`, и иногда дополнительно вводят `effective_from` если нужно хранить бизнес-время отдельно.

### Как работает

Правило вставки в satellite обычно такое:

- если по данному `*_hk` пришла запись, и её `hashdiff` отличается от последнего `hashdiff`, создаётся новая версия (новая строка);
    
- если `hashdiff` совпадает, запись считается дублем и не создаёт новую версию.
    

Это защищает от:

- повторной поставки одних и тех же данных,
    
- повторных прогонов пайплайна,
    
- ситуации “источник ретраит отправку”.
    

### Проблемы и ограничения

Hashdiff корректен только при строгих правилах нормализации:

- одинаковые данные должны давать одинаковый хэш (trim, нормализация null, единые форматы дат/чисел);
    
- порядок полей в хэше должен быть фиксирован;
    
- набор атрибутов, участвующий в hashdiff, должен быть стабилен по версии satellite.
    

Если эти правила нарушены, DV начинает “штамповать версии” без реальных изменений или, наоборот, пропускать изменения. Вторая проблема — конфликтующие источники: два источника могут прислать разные атрибуты на один и тот же бизнес-ключ. Без record_source и правил приоритета невозможно корректно собрать представление.

### Практические аспекты

Обычно разделяют:

- satellites “как пришло” (raw-ish) — почти прямое отражение источника;
    
- satellites “стандартизованные” — уже с приведением типов/форматов, чтобы hashdiff был устойчив.
    

Также часто хранят “последнюю версию” как представление или PIT-таблицу, чтобы ускорить сборку потребительских моделей.

### Схема логики версий satellite

```text
SAT (entity_hk, load_ts, hashdiff, attrs...)

load_ts: 10:00  hashdiff: AAA  attrs: ...
load_ts: 10:05  hashdiff: AAA  attrs: ...   -> дубль, не вставляем
load_ts: 11:20  hashdiff: BBB  attrs: ...   -> изменение, вставляем новую строку

Итог: история = последовательность уникальных hashdiff во времени загрузки
```

---

## Слайд 14. DV → Star: сборка измерений и фактов из Hubs/Links/Satellites

### Суть концепции

DV редко является конечным слоем потребления. Чтобы получить удобные BI/ML-наборы, DV проецируют в Star Schema или в широкие витрины. Этот шаг — преобразование нормализованной модели интеграции в модель потребления, где:

- измерения содержат атрибуты в удобном виде (обычно “последняя версия” или “версия на момент”),
    
- факты собираются из links (отношения/события) и satellites (атрибуты событий).
    

### Как работает

Построение dimension из DV:

- ключ измерения берут из hub (hk),
    
- бизнес-ключ и атрибуты — из satellite,
    
- выбирают версию атрибутов: “текущая” или “as-of time”.
    

Построение fact из DV:

- фактовая “ось” часто соответствует link (отношение между сущностями),
    
- меры и временные поля приходят из satellite link’а или satellite сущности события,
    
- внешние ключи на измерения — hk участников link.
    

Чтобы сделать это эффективно, используют ускорители:

- **PIT (Point-In-Time)**: таблица/представление, которое для каждого hk фиксирует ссылки на актуальные версии satellites на конкретный момент времени.
    
- **Bridge**: таблица для сложных связей many-to-many и исторических соответствий.
    

### Проблемы и ограничения

Сборка Star из DV может быть тяжёлой по join, если пытаться каждый раз “на лету” искать последние версии satellites. PIT/Bridge вводят дополнительный слой данных, который нужно поддерживать, но они резко упрощают и ускоряют потребительские запросы и трансформации.

Ещё одна проблема — выбор “истины”: если satellites приходят из нескольких источников, нужно формализовать правила приоритета или объединения, иначе одно и то же измерение будет собираться по-разному в разных витринах.

### Схема преобразования DV → Star

```text
Data Vault                                  Star Schema

HUB_USER + SAT_USER_ATTR  ----->  DIM_USER (user_key, attrs...)

HUB_EVENT + SAT_EVENT_ATTR -----> DIM_EVENT (event_key, attrs...)

LINK_USER_EVENT + SAT_*   ----->  FACT_EVENTS (FKs to dims, measures)
```

```text
Поток сборки:
HUB (ключи) + SAT (атрибуты/версии) -> DIM
LINK (отношения) + SAT (атрибуты)   -> FACT
```

---

## Слайд 15. Выбор подхода и типовые ошибки: Star vs DV vs SCD

### Суть концепции

Star Schema и Data Vault решают разные задачи. Star — для стабильного потребления и быстрых запросов. DV — для устойчивой интеграции и полной истории поставки. SCD — механизм историзации атрибутов измерений в потребительской модели. Ошибки возникают, когда выбирают инструмент не под задачу или смешивают цели слоёв.

### Как работает (как выбирать)

Практическая логика выбора:

- если нужно быстро и стабильно обслуживать BI с понятными метриками и ограниченным числом источников — основой становится Star/витрины, а историзацию решают через SCD;
    
- если источников много, они нестабильны, важен аудит “что пришло”, и нужно часто менять правила сборки потребительских представлений — DV даёт устойчивый интеграционный слой, после чего всё равно строятся Star/витрины;
    
- если атрибуты сущностей меняются во времени и это важно для ретроспективы — нужна SCD (в Star) или satellites (в DV), и далее корректный as-of join.
    

### Типовые ошибки (структурные, а не “плохой код”)

1. **Нет grain**  
    Таблицы не имеют определённого ключа зерна → join и агрегации дают непредсказуемый результат.
    
2. **Измерение не уникально по бизнес-ключу**  
    many-to-many join раздувает факт → двойной счёт и деградация производительности.
    
3. **SCD2 без корректного as-of**  
    Факты присоединяются к “текущим” атрибутам → перекраска истории и несравнимые периоды.
    
4. **DV как слой BI**  
    Попытка строить отчёты напрямую на DV → много join, высокая стоимость запросов, сложность семантики.
    
5. **DV без дисциплины satellites/hashdiff**  
    История превращается в дубли или хаос версий, невозможно собрать устойчивые измерения.
    

### Схема “правильного разделения слоёв”

```text
INTEGRATION (гибкость, аудит)        CONSUMPTION (простота, скорость)
Data Vault (H/L/S)        ----->     Star Schema / Wide Marts (Facts+Dims)

История в DV: satellites
История в Star: SCD
```

Если продолжать в том же стиле, следующий шаг — отдельно развернуть SCD (Type 1/2/3) со схемами **as-of join** и правилами интервалов, потому что именно там чаще всего ломаются ретроспективные отчёты.